<!DOCTYPE html>

<html>
<head>
<title>How was the normal distribution derived?</title>
<link href="https://cdn.sstatic.net/Shared/stacks.css?v=079c5e1603be" rel="stylesheet" type="text/css"/>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript"> </script>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap.min.css" rel="stylesheet"/>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap-theme.min.css" rel="stylesheet"/>
<style>
        .row {
          display: block;
          margin-left: auto;
          margin-right: auto;
          width:50%;
        }
        tr {
          border:1px solid lightgrey;
        }
        </style>
</head>
<body>
<div>
<div class="row" id="question-title">
<h1> How was the normal distribution derived? </h1>
<hr/>
</div>
<div class="row">
<div class="question">
<div id="question" question_id="384893">
<p>Abraham de Moivre, when he came up with this formula, had to assure that the points of inflection were exactly one standard deviation away from the center, and so that it was bell-shaped, as well as make sure that the area under the curve was exactly equal to one.</p> <p>And somehow they came up with the standard normal distribution, which is as follows:</p> <p><span class="math-container" id="4088081" visual_id="973300"><math alttext="\displaystyle\phi(x)=\frac{1}{\sqrt{2\pi}}e^{-\dfrac{1}{2}x^{2}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>œï</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><msqrt><mrow><mn>2</mn><mo>‚Å¢</mo><mi>œÄ</mi></mrow></msqrt></mfrac></mstyle><mo>‚Å¢</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mstyle displaystyle="true" scriptlevel="-1"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>‚Å¢</mo><msup><mi>x</mi><mn>2</mn></msup></mrow></mrow></msup></mrow></mrow></semantics></math></span></p> <p>And even cooler, he found the distribution for when the mean was not <span class="math-container" id="4088082" visual_id="92"><math alttext="0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn></semantics></math></span> and the standard deviation was not <span class="math-container" id="4088083" visual_id="342"><math alttext="1" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn></semantics></math></span>, and came up with:</p> <p><span class="math-container" id="4088084" visual_id="911144"><math alttext="\displaystyle f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\dfrac{(x-\mu)^{2}}{2\sigma^% {2}}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>f</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mrow><mi>œÉ</mi><mo>‚Å¢</mo><msqrt><mrow><mn>2</mn><mo>‚Å¢</mo><mi>œÄ</mi></mrow></msqrt></mrow></mfrac></mstyle><mo>‚Å¢</mo><msup><mi>e</mi><mrow><mo>-</mo><mstyle displaystyle="true" scriptlevel="-1"><mfrac><msup><mrow><mo stretchy="false">(</mo><mrow><mi>x</mi><mo>-</mo><mi>Œº</mi></mrow><mo stretchy="false">)</mo></mrow><mn>2</mn></msup><mrow><mn>2</mn><mo>‚Å¢</mo><msup><mi>œÉ</mi><mn>2</mn></msup></mrow></mfrac></mstyle></mrow></msup></mrow></mrow></semantics></math></span></p> <p>And so what I ask is, how? How was an equation come up with that fit all the aforementioned criteria? Moreover, how do the numbers <span class="math-container" id="4088085" visual_id="1294"><math alttext="\pi" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÄ</mi></semantics></math></span> and <span class="math-container" id="4088086" visual_id="1073"><math alttext="e" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>e</mi></semantics></math></span> come into this?</p>
</div>
<hr/>
<div id="tags">
<span> statistics </span><span> probability-distributions </span><span> math-history </span><span> normal-distribution </span>
</div>
<hr/>
<div id="question-comments">
<table>
<tbody>
<tr><td comment_id="823757"> For your last question: <span class="math-container" id="4088122" visual_id="1294"><math alttext="\pi" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÄ</mi></semantics></math></span> appears as a normalizing factor.  It's a typically exercise in multi-variable calculus to integrate <span class="math-container" id="4088088" visual_id="7325"><math alttext="e^{x^{2}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>e</mi><msup><mi>x</mi><mn>2</mn></msup></msup></semantics></math></span> over the whole real line line, and this integral is similar.  As well, the <span class="math-container" id="4088139" visual_id="1073"><math alttext="e" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>e</mi></semantics></math></span> is not surprising: if we want our function to have finite definite integral over the real line (yet not have compact support!), exponential decay is the easiest way for this to occur.  If you use an exponential, it is almost always <span class="math-container" id="4088139" visual_id="1073"><math alttext="e" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>e</mi></semantics></math></span>. </td></tr><tr><td comment_id="823781"> https://en.wikipedia.org/wiki/Normal_distribution#History and references </td></tr><tr><td comment_id="3470157"> It's not difficult to make the integral be <span class="math-container" id="4088186" visual_id="342"><math alttext="1" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn></semantics></math></span> once you have a positive function such that <span class="math-container" id="4088092" visual_id="6597395"><math alttext="\int_{\mathbb{R}}f(x)dx&lt;+\infty" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mo largeop="true" symmetric="true">‚à´</mo><mi>‚Ñù</mi></msub><mrow><mi>f</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo>‚Å¢</mo><mrow><mo rspace="0pt">ùëë</mo><mi>x</mi></mrow></mrow></mrow><mo>&lt;</mo><mrow><mo>+</mo><mi mathvariant="normal">‚àû</mi></mrow></mrow></semantics></math></span> </td></tr><tr><td comment_id="3816613"> take a look at this link https://www.sonoma.edu/users/w/wilsonst/papers/Normal/default.html </td></tr><tr><td comment_id="3873953"> I really like this article's take on Gauss' proof: https://www.maa.org/sites/default/files/pdf/upload_library/22/Allendoerfer/stahl96.pdf </td></tr><tr><td comment_id="5806234"> @ClockSlave I'm worried that the integral in that document is incorrect. They seem to get a different result than [Wolfram Alpha](http://www.wolframalpha.com/input/?i=df(x)+%2Fdx+%3D+-k+(x-m)+f(x)) which worries me. </td></tr><tr><td comment_id="5806782"> @Chris I think a summary of the proof would make for a great answer. Thank you for the link! </td></tr>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div class="answer">
<div answer_id="3044453" id="answer">
<p>The Normal distribution came about from approximations of the binomial distribution (de Moivre), from linear regression (Gauss), and from the central limit theorem. The derivation given by Tim relates more closely to the linear regression derivation, where the amount of error is represented by a Normal distribution when errors are assumed symmetric about a mean, and to decrease away from the mean. I used Tim's answer and made it a little more formal.</p> <hr/> <p>Theorem: <strong>Two identically distributed independent random variables</strong> follow a distribution, called the <em>normal distribution,</em> given that their probability density functions (PDFs) are known to be continuous and differentiable, symmetric about a mean, and decrease towards zero away from the mean. </p> <p>Proof: Let <span class="math-container" id="4088140" visual_id="115"><math alttext="X" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi></semantics></math></span> and <span class="math-container" id="4088141" visual_id="375"><math alttext="Y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi></semantics></math></span> be identically distributed independent random variables with continuous and differentiable PDFs. It is assumed that the PDFs are even functions, for example <span class="math-container" id="4088142" visual_id="543552"><math alttext="f_{X}(x)=f_{X}(-x)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mrow><mo>-</mo><mi>x</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></semantics></math></span>, and <span class="math-container" id="4088143" visual_id="6597409"><math alttext="f_{X}(x)\rightarrow 0\text{ as }x\rightarrow\pm\infty" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>‚Üí</mo><mrow><mn>0</mn><mo>‚Å¢</mo><mtext>¬†as¬†</mtext><mo>‚Å¢</mo><mi>x</mi></mrow><mo>‚Üí</mo><mrow><mo>¬±</mo><mi mathvariant="normal">‚àû</mi></mrow></mrow></semantics></math></span>.  </p> <p>Their joint PDF, because of their independence, is <span class="math-container" id="4088144" visual_id="951994"><math alttext="f_{XY}(x,y)=f_{X}(x)f_{Y}(y)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>f</mi><mrow><mi>X</mi><mo>‚Å¢</mo><mi>Y</mi></mrow></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo>‚Å¢</mo><msub><mi>f</mi><mi>Y</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></semantics></math></span>. Because they are identically distributed and symmetric, only the <em>norm</em> or magnitude of the two variables is unique - that is, <span class="math-container" id="4088145" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span> and <span class="math-container" id="4088146" visual_id="68"><math alttext="y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi></semantics></math></span> can be interchanged with no effect on the final probability. They are identically distributed and symmetric, figuratively related to a circle, as opposed to the unequally distributed oval. Therefore, there must exist a function <span class="math-container" id="4088147" visual_id="51473"><math alttext="g(r)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> such that <span class="math-container" id="4088148" visual_id="6597410"><math alttext="f_{XY}(x,y)=g(\sqrt{x^{2}+y^{2}})" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>f</mi><mrow><mi>X</mi><mo>‚Å¢</mo><mi>Y</mi></mrow></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><msqrt><mrow><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup></mrow></msqrt><mo stretchy="false">)</mo></mrow></mrow></mrow></semantics></math></span> Which, because <span class="math-container" id="4088149" visual_id="627"><math alttext="g" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi></semantics></math></span> is not yet determined, is equivalent to <span class="math-container" id="4088150" visual_id="6597411"><math alttext="f_{XY}(x,y)=g(x^{2}+y^{2})." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><msub><mi>f</mi><mrow><mi>X</mi><mo>‚Å¢</mo><mi>Y</mi></mrow></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mrow><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></semantics></math></span></p> <p>From the definition of the joint distribution, <span class="math-container" id="4088151" visual_id="6597412"><math alttext="f_{X}(x)f_{Y}(y)=g(x^{2}+y^{2})." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo>‚Å¢</mo><msub><mi>f</mi><mi>Y</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mrow><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></semantics></math></span> Which, for <span class="math-container" id="4088152" visual_id="3870"><math alttext="y=0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mn>0</mn></mrow></semantics></math></span>, gives <span class="math-container" id="4088153" visual_id="6597413"><math alttext="f_{X}(x)\propto g(x^{2})." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>‚àù</mo><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></semantics></math></span> Assuming <span class="math-container" id="4088154" visual_id="6597414"><math alttext="=-\frac{1}{2}\int_{0}^{1}\log\left(u\right)\frac{u^{2}}{1-u}du-\frac{1}{6}=" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi></mi><mo>=</mo><mrow><mrow><mo>-</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>‚Å¢</mo><mrow><msubsup><mo largeop="true" symmetric="true">‚à´</mo><mn>0</mn><mn>1</mn></msubsup><mrow><mrow><mi>log</mi><mo>‚Å°</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow><mo>‚Å¢</mo><mfrac><msup><mi>u</mi><mn>2</mn></msup><mrow><mn>1</mn><mo>-</mo><mi>u</mi></mrow></mfrac><mo>‚Å¢</mo><mrow><mo rspace="0pt">ùëë</mo><mi>u</mi></mrow></mrow></mrow></mrow></mrow><mo>-</mo><mfrac><mn>1</mn><mn>6</mn></mfrac></mrow><mo>=</mo><mi></mi></mrow></semantics></math></span> is a constant. Similar argument gives <span class="math-container" id="4088155" visual_id="6597415"><math alttext="f_{Y}(y)\propto g(y^{2})." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><msub><mi>f</mi><mi>Y</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>‚àù</mo><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><msup><mi>y</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>.</mo></mrow></semantics></math></span> These last two results are significant, because substitution shows that the product of <span class="math-container" id="4088156" visual_id="6597416"><math alttext="g(x^{2})g(y^{2})" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><mo>‚Å¢</mo><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><msup><mi>y</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> is proportional to the sum <span class="math-container" id="4088157" visual_id="3705423"><math alttext="g(x^{2}+y^{2})" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mrow><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup></mrow><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span>: <span class="math-container" id="4088158" visual_id="6597417"><math alttext="g(x^{2})g(y^{2})\propto g(x^{2}+y^{2})" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><mo>‚Å¢</mo><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><msup><mi>y</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></mrow><mo>‚àù</mo><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mrow><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></semantics></math></span> And it is known from algebra that the only function to have this property is the exponential function (and the natural logarithm). </p> <p>This is to say, <span class="math-container" id="4088159" visual_id="51473"><math alttext="g(r)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> will be some type of exponential,  <span class="math-container" id="4088160" visual_id="6597418"><math alttext="g(r)=Ae^{Br}." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>A</mi><mo>‚Å¢</mo><msup><mi>e</mi><mrow><mi>B</mi><mo>‚Å¢</mo><mi>r</mi></mrow></msup></mrow></mrow><mo>.</mo></mrow></semantics></math></span> Where <span class="math-container" id="4088161" visual_id="188"><math alttext="A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi></semantics></math></span> and <span class="math-container" id="4088162" visual_id="599"><math alttext="B" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi></semantics></math></span> are constants yet to be determined. We assume, now, that wherever the expected value is, the probability of error away from this expected value with decrease. That is to say, we expect that the chance of error should be minimum near the expected value, and decrease to zero away from this value. Another way of saying this is that the mean must be the maximum of <span class="math-container" id="4088163" visual_id="51473"><math alttext="g(r)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span>, and yet another way of saying this is that <span class="math-container" id="4088164" visual_id="51473"><math alttext="g(r)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> must approach <span class="math-container" id="4088165" visual_id="92"><math alttext="0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn></semantics></math></span> as <span class="math-container" id="4088166" visual_id="907468"><math alttext="r\rightarrow\pm\infty" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>‚Üí</mo><mrow><mo>¬±</mo><mi mathvariant="normal">‚àû</mi></mrow></mrow></semantics></math></span>. In any case, we need the argument to the exponential to be negative.  <span class="math-container" id="4088167" visual_id="6597419"><math alttext="g(r)=Ae^{-Br}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>A</mi><mo>‚Å¢</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>B</mi><mo>‚Å¢</mo><mi>r</mi></mrow></mrow></msup></mrow></mrow></semantics></math></span></p> <p>Now if we return to our joint PDF,  <span class="math-container" id="4088168" visual_id="6597420"><math alttext="f_{XY}(x,y)=f_{X}(x)f_{Y}(y)=g(x^{2}+y^{2})" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>f</mi><mrow><mi>X</mi><mo>‚Å¢</mo><mi>Y</mi></mrow></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo>‚Å¢</mo><msub><mi>f</mi><mi>Y</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mrow><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><msup><mi>y</mi><mn>2</mn></msup></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></semantics></math></span> Here again, we can investigate the PDF of <span class="math-container" id="4088169" visual_id="28895"><math alttext="f_{X}(x)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> alone by setting <span class="math-container" id="4088170" visual_id="3870"><math alttext="y=0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mn>0</mn></mrow></semantics></math></span>, <span class="math-container" id="4088171" visual_id="6597421"><math alttext="f_{X}(x)\propto g(x^{2})=Ae^{-Bx^{2}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>‚àù</mo><mrow><mi>g</mi><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><msup><mi>x</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>A</mi><mo>‚Å¢</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>B</mi><mo>‚Å¢</mo><msup><mi>x</mi><mn>2</mn></msup></mrow></mrow></msup></mrow></mrow></semantics></math></span> Note that the mean of this distribution is <span class="math-container" id="4088172" visual_id="92"><math alttext="0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn></semantics></math></span>. In order to give a mean of <span class="math-container" id="4088173" visual_id="2258"><math alttext="\mu" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œº</mi></semantics></math></span>, this distribution becomes <span class="math-container" id="4088174" visual_id="6597422"><math alttext="f_{X}(x)\propto Ae^{-B(x-\mu)^{2}}." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>‚àù</mo><mrow><mi>A</mi><mo>‚Å¢</mo><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>B</mi><mo>‚Å¢</mo><msup><mrow><mo stretchy="false">(</mo><mrow><mi>x</mi><mo>-</mo><mi>Œº</mi></mrow><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></mrow></mrow></msup></mrow></mrow><mo>.</mo></mrow></semantics></math></span></p> <p>The constants are determined from the fact that the integral of the PDF <span class="math-container" id="4088175" visual_id="28895"><math alttext="f_{X}(x)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> must be equal to 1 for the entire domain. That is, the cumulative distribution function (CDF) must approach 1 at the upper limit (probability cannot be &gt;100%).  <span class="math-container" id="4088176" visual_id="1632120"><math alttext="\int_{0}^{\infty}f_{X}(x)dx=1" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msubsup><mo largeop="true" symmetric="true">‚à´</mo><mn>0</mn><mi mathvariant="normal">‚àû</mi></msubsup><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo>‚Å¢</mo><mrow><mo rspace="0pt">ùëë</mo><mi>x</mi></mrow></mrow></mrow><mo>=</mo><mn>1</mn></mrow></semantics></math></span> The integral of <span class="math-container" id="4088177" visual_id="2124109"><math alttext="e^{-Bx^{2}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>B</mi><mo>‚Å¢</mo><msup><mi>x</mi><mn>2</mn></msup></mrow></mrow></msup></semantics></math></span> is <span class="math-container" id="4088178" visual_id="6597423"><math alttext="\sqrt{\frac{\pi}{B}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msqrt><mfrac><mi>œÄ</mi><mi>B</mi></mfrac></msqrt></semantics></math></span>, thus <span class="math-container" id="4088179" visual_id="6597424"><math alttext="A\int_{0}^{\infty}e^{-Bx^{2}}dx=A\sqrt{\frac{\pi}{B}}=1" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>A</mi><mo>‚Å¢</mo><mrow><msubsup><mo largeop="true" symmetric="true">‚à´</mo><mn>0</mn><mi mathvariant="normal">‚àû</mi></msubsup><mrow><msup><mi>e</mi><mrow><mo>-</mo><mrow><mi>B</mi><mo>‚Å¢</mo><msup><mi>x</mi><mn>2</mn></msup></mrow></mrow></msup><mo>‚Å¢</mo><mrow><mo rspace="0pt">ùëë</mo><mi>x</mi></mrow></mrow></mrow></mrow><mo>=</mo><mrow><mi>A</mi><mo>‚Å¢</mo><msqrt><mfrac><mi>œÄ</mi><mi>B</mi></mfrac></msqrt></mrow><mo>=</mo><mn>1</mn></mrow></semantics></math></span> <span class="math-container" id="4088180" visual_id="6597425"><math alttext="A=\sqrt{\frac{B}{\pi}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><msqrt><mfrac><mi>B</mi><mi>œÄ</mi></mfrac></msqrt></mrow></semantics></math></span> The constant <span class="math-container" id="4088181" visual_id="599"><math alttext="B" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi></semantics></math></span> is, for convenience, substituted by <span class="math-container" id="4088182" visual_id="6597426"><math alttext="\sigma^{2}=\frac{1}{2B}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>œÉ</mi><mn>2</mn></msup><mo>=</mo><mfrac><mn>1</mn><mrow><mn>2</mn><mo>‚Å¢</mo><mi>B</mi></mrow></mfrac></mrow></semantics></math></span>, so that <span class="math-container" id="4088183" visual_id="6597427"><math alttext="A=\frac{1}{\sqrt{2\pi\sigma^{2}}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mfrac><mn>1</mn><msqrt><mrow><mn>2</mn><mo>‚Å¢</mo><mi>œÄ</mi><mo>‚Å¢</mo><msup><mi>œÉ</mi><mn>2</mn></msup></mrow></msqrt></mfrac></mrow></semantics></math></span> and <span class="math-container" id="4088184" visual_id="6597428"><math alttext="f_{X}(x)=\frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><msub><mi>f</mi><mi>X</mi></msub><mo>‚Å¢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><msqrt><mrow><mn>2</mn><mo>‚Å¢</mo><mi>œÄ</mi><mo>‚Å¢</mo><msup><mi>œÉ</mi><mn>2</mn></msup></mrow></msqrt></mfrac><mo>‚Å¢</mo><msup><mi>e</mi><mrow><mo>-</mo><mfrac><msup><mrow><mo stretchy="false">(</mo><mrow><mi>x</mi><mo>-</mo><mi>Œº</mi></mrow><mo stretchy="false">)</mo></mrow><mn>2</mn></msup><mrow><mn>2</mn><mo>‚Å¢</mo><msup><mi>œÉ</mi><mn>2</mn></msup></mrow></mfrac></mrow></msup></mrow></mrow><mo>.</mo></mrow></semantics></math></span> Which is, of course, the common form of what is known as the Normal distribution. Note that the proportional symbol became an equals sign, which is necessary from the assumption that <span class="math-container" id="4088185" visual_id="115"><math alttext="X" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi></semantics></math></span> is a random variable, and all random variables have a PDF which integrates to <span class="math-container" id="4088186" visual_id="342"><math alttext="1" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn></semantics></math></span>. This proves the theorem.</p> <p>One will find that <span class="math-container" id="4088187" visual_id="3528"><math alttext="\sigma^{2}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>œÉ</mi><mn>2</mn></msup></semantics></math></span> is called the variation, and <span class="math-container" id="4088188" visual_id="668669"><math alttext="sigma" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>‚Å¢</mo><mi>i</mi><mo>‚Å¢</mo><mi>g</mi><mo>‚Å¢</mo><mi>m</mi><mo>‚Å¢</mo><mi>a</mi></mrow></semantics></math></span> is the standard deviation. The parameters <span class="math-container" id="4088189" visual_id="3528"><math alttext="\sigma^{2}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>œÉ</mi><mn>2</mn></msup></semantics></math></span> and <span class="math-container" id="4088190" visual_id="2258"><math alttext="\mu" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œº</mi></semantics></math></span>, that is, the variation and the mean, may be chosen arbitrarily, and uniquely define the distribution. </p> <hr/> <p>It's a beautiful thing - without knowing much about the random variables, other than the fact that they are independent, and come from the same symmetric distribution, we can logically determine the distribution they come from. </p> <p><em>To write this answer, I followed the references supplied in comments of the question, the description given by Tim, and various online resources such as Wikipedia. Therefore, the proof may not be rigorous, and may contain errors. The errors are certainly mine alone, due to misinterpretations and/or miscalculations.</em> </p>
</div>
<hr/>
<div id="answer-comments">
<table>
<tbody>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div id="duplicate">
<table>
<tbody>
</tbody>
</table>
</div>
<hr/>
<div id="related">
<table>
<tbody>
<tr><td post_id="2683282"> Exponential formula in the derivation of the Gaussian distribution </td></tr>
</tbody>
</table>
</div>
</div>
</div>
</body>
</html>
