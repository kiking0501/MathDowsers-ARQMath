<!DOCTYPE html>

<html>
<head>
<title>How to calculate the hessian of a matrix function</title>
<link href="https://cdn.sstatic.net/Shared/stacks.css?v=079c5e1603be" rel="stylesheet" type="text/css"/>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript"> </script>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap.min.css" rel="stylesheet"/>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap-theme.min.css" rel="stylesheet"/>
<style>
        .row {
          display: block;
          margin-left: auto;
          margin-right: auto;
          width:50%;
        }
        tr {
          border:1px solid lightgrey;
        }
        </style>
</head>
<body>
<div>
<div class="row" id="question-title">
<h1> How to calculate the hessian of a matrix function </h1>
<hr/>
</div>
<div class="row">
<div class="question">
<div id="question" question_id="371255">
<p>I am estimating a model minimizing the following objective function, </p> <p><span class="math-container" id="3953907" visual_id="1520419"><math alttext="M(\theta)=(Z^{\prime}G(\theta))^{\prime}W(Z^{\prime}G(\theta))" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>M</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msup><mrow><mo stretchy="false">(</mo><mrow><msup><mi>Z</mi><mo>′</mo></msup><mo>⁢</mo><mi>G</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow><mo>′</mo></msup><mo>⁢</mo><mi>W</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><msup><mi>Z</mi><mo>′</mo></msup><mo>⁢</mo><mi>G</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow></semantics></math></span> </p> <p><span class="math-container" id="3953908" visual_id="388"><math alttext="Z" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Z</mi></semantics></math></span> is an <span class="math-container" id="3953909" visual_id="1520420"><math alttext="N\times L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>L</mi></mrow></semantics></math></span> matrix of data, and <span class="math-container" id="3953910" visual_id="304"><math alttext="W" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi></semantics></math></span> is an <span class="math-container" id="3953911" visual_id="307937"><math alttext="L\times L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>×</mo><mi>L</mi></mrow></semantics></math></span> weight matrix, neither of which depends on <span class="math-container" id="3953912" visual_id="206"><math alttext="\theta" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>θ</mi></semantics></math></span>. <span class="math-container" id="3953913" visual_id="655213"><math alttext="G(\theta)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> is a function which takes the <span class="math-container" id="3953914" visual_id="586422"><math alttext="K\times 1" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>×</mo><mn>1</mn></mrow></semantics></math></span> vector of parameters I am estimating into an <span class="math-container" id="3953915" visual_id="785"><math alttext="N\times 1" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mn>1</mn></mrow></semantics></math></span> vector of residuals. </p> <p>I am trying to calculate the Gradient and the Hessian of M to feed to into a Matlab solver (<span class="math-container" id="3953916" visual_id="655213"><math alttext="G(\theta)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> is highly nonlinear). I believe I have the gradient correctly calculated as follows. Let <span class="math-container" id="3953917" visual_id="1520421"><math alttext="J=dG/d\theta" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>=</mo><mrow><mrow><mrow><mi>d</mi><mo>⁢</mo><mi>G</mi></mrow><mo>/</mo><mi>d</mi></mrow><mo>⁢</mo><mi>θ</mi></mrow></mrow></semantics></math></span> be an <span class="math-container" id="3953918" visual_id="527680"><math alttext="N\times K" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>K</mi></mrow></semantics></math></span> Jacobian matrix, where <span class="math-container" id="3953919" visual_id="789064"><math alttext="J_{i,k}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>J</mi><mrow><mi>i</mi><mo>,</mo><mi>k</mi></mrow></msub></semantics></math></span> is the derivative of element <span class="math-container" id="3953920" visual_id="158"><math alttext="i" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi></semantics></math></span> of <span class="math-container" id="3953921" visual_id="673"><math alttext="G" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>G</mi></semantics></math></span> with respect to parameter <span class="math-container" id="3953922" visual_id="83"><math alttext="k" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi></semantics></math></span>. Then the gradient vector of M is, </p> <p><span class="math-container" id="3953923" visual_id="1520422"><math alttext="\nabla M=2(Z^{\prime}J(\theta))^{\prime}W(Z^{\prime}G(\theta))^{\prime}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo>∇</mo><mo>⁡</mo><mi>M</mi></mrow><mo>=</mo><mrow><mn>2</mn><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mrow><msup><mi>Z</mi><mo>′</mo></msup><mo>⁢</mo><mi>J</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow><mo>′</mo></msup><mo>⁢</mo><mi>W</mi><mo>⁢</mo><msup><mrow><mo stretchy="false">(</mo><mrow><msup><mi>Z</mi><mo>′</mo></msup><mo>⁢</mo><mi>G</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow><mo stretchy="false">)</mo></mrow><mo>′</mo></msup></mrow></mrow></semantics></math></span> </p> <p>However, I cannot figure out how to take the derivative of this gradient to get the Hessian. I can calculate the vectors of derivatives of each element of <span class="math-container" id="3953924" visual_id="15822"><math alttext="J(\theta)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span>, but I'm not sure what the order of that derivative matrix should be. I see that I basically need to divide this function up into two parts and use a the product rule, but cannot figure out what the derivative of each part should look like. </p> <p>Any help would be greatly appreciated. Thank you.</p>
</div>
<hr/>
<div id="tags">
<span> linear-algebra </span><span> optimization </span><span> matlab </span>
</div>
<hr/>
<div id="question-comments">
<table>
<tbody>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div class="answer">
<div answer_id="564113" id="answer">
<p>I was having similar issues with an equation as the second derivative evaluation was not possible.</p> <p><a href="http://sentientdesigns.net/math/mathbooks/Number%20theory/Numerical%20Optimization%20-%20J.%20Nocedal,%20S.%20Wright.pdf" rel="nofollow">Numerical Optimization by J Nocedal &amp; S Wright</a></p> <p>And <a href="http://users-phys.au.dk/jensjh/numeric/project/10.1.1.135.865.pdf" rel="nofollow">The Levenberg-Marquardt Algorithm by Ananth Ranganathan</a></p> <p>suggest that the Hessian and Gradient can be approximated rather than directly evaluated. The Hessian can be approximated as the transpose of the Jacobian multiplied by the Jacobian itself. The Gradient can be approximated by the transpose of the Jacobian multiplied by the Residuals.</p> <p>I hope this is some use to you or points you in a more helpful direction.</p>
</div>
<hr/>
<div id="answer-comments">
<table>
<tbody>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div id="duplicate">
<table>
<tbody>
</tbody>
</table>
</div>
<hr/>
<div id="related">
<table>
<tbody>
</tbody>
</table>
</div>
</div>
</div>
</body>
</html>
