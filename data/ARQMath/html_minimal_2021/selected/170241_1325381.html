<!DOCTYPE html>

<html>
<head>
<title>When is matrix multiplication commutative?</title>
<link href="https://cdn.sstatic.net/Shared/stacks.css?v=079c5e1603be" rel="stylesheet" type="text/css"/>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript"> </script>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap.min.css" rel="stylesheet"/>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap-theme.min.css" rel="stylesheet"/>
<style>
        .row {
          display: block;
          margin-left: auto;
          margin-right: auto;
          width:50%;
        }
        tr {
          border:1px solid lightgrey;
        }
        </style>
</head>
<body>
<div>
<div class="row" id="question-title">
<h1> When is matrix multiplication commutative? </h1>
<hr/>
</div>
<div class="row">
<div class="question">
<div id="question" question_id="170241">
<p>I know that matrix multiplication in general is not commutative. So, in general:</p> <p><span class="math-container" id="1978531" visual_id="7613440"><math alttext="A,B\in\mathbb{R}^{n\times n}:A\cdot B\neq B\cdot A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><mi>A</mi><mo>,</mo><mi>B</mi></mrow><mo>∈</mo><msup><mi>ℝ</mi><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><mo>:</mo><mrow><mrow><mi>A</mi><mo>⋅</mo><mi>B</mi></mrow><mo>≠</mo><mrow><mi>B</mi><mo>⋅</mo><mi>A</mi></mrow></mrow></mrow></semantics></math></span></p> <p>But for some matrices, this equations holds, e.g. A = Identity or A = Null-matrix <span class="math-container" id="1978532" visual_id="7613441"><math alttext="\forall B\in\mathbb{R}^{n\times n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo>∀</mo><mi>B</mi></mrow><mo>∈</mo><msup><mi>ℝ</mi><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow></semantics></math></span>.</p> <p>I think I remember that a group of special matrices (was it <span class="math-container" id="1978533" visual_id="4003"><math alttext="O(n)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span>, the <a href="http://en.wikipedia.org/wiki/Orthogonal_group">group of orthogonal matrices</a>?) exist, for which matrix multiplication is commutative.</p> <p><strong>For which matrices <span class="math-container" id="1978534" visual_id="120952"><math alttext="A,B\in\mathbb{R}^{n\times n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>A</mi><mo>,</mo><mi>B</mi></mrow><mo>∈</mo><msup><mi>ℝ</mi><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow></semantics></math></span> is <span class="math-container" id="1978535" visual_id="671480"><math alttext="A\cdot B=B\cdot A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>A</mi><mo>⋅</mo><mi>B</mi></mrow><mo>=</mo><mrow><mi>B</mi><mo>⋅</mo><mi>A</mi></mrow></mrow></semantics></math></span>?</strong></p>
</div>
<hr/>
<div id="tags">
<span> linear-algebra </span><span> matrices </span>
</div>
<hr/>
<div id="question-comments">
<table>
<tbody>
<tr><td comment_id="391221"> A sufficient condition is that <span class="math-container" id="1978621" visual_id="188"><math alttext="A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi></semantics></math></span> and <span class="math-container" id="1978575" visual_id="599"><math alttext="B" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi></semantics></math></span> are simultaneously diagonalizable. </td></tr><tr><td comment_id="391234"> possible duplicate of [Given a matrix, is there always another matrix which commutes with it?](http://math.stackexchange.com/questions/92480/given-a-matrix-is-there-always-another-matrix-which-commutes-with-it) </td></tr><tr><td comment_id="391310"> <span class="math-container" id="1978538" visual_id="23795"><math alttext="SO(2)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>⁢</mo><mi>O</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> is commutative, but that is more of an accident than a general property of (special) orthogonal groups. </td></tr><tr><td comment_id="391439"> @JohannesKloos That was what I was looking for. If you post it as an answer, I'll accept it. </td></tr><tr><td comment_id="391510"> I'm not aware of any general statement in this case. </td></tr><tr><td comment_id="391530"> what if A and/or B are/is not diagonalizable, i.e. what's the condition for undiagonalizable matrices to commute? </td></tr><tr><td comment_id="392271"> @chaohuang if <span class="math-container" id="1978621" visual_id="188"><math alttext="A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi></semantics></math></span> and <span class="math-container" id="1978575" visual_id="599"><math alttext="B" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi></semantics></math></span> commute, then for any eigenvalue <span class="math-container" id="1978555" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span>, of <span class="math-container" id="1978621" visual_id="188"><math alttext="A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi></semantics></math></span>, we must have not only that the <span class="math-container" id="1978555" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span>-eigenspace <span class="math-container" id="1978544" visual_id="7613442"><math alttext="\ker\lambda I-A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ker</mi><mo>⁡</mo><mrow><mi>λ</mi><mo>⁢</mo><mi>I</mi></mrow></mrow><mo>-</mo><mi>A</mi></mrow></semantics></math></span> is preserved by <span class="math-container" id="1978575" visual_id="599"><math alttext="B" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi></semantics></math></span> (because if <span class="math-container" id="1978546" visual_id="115"><math alttext="X" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi></semantics></math></span> and <span class="math-container" id="1978547" visual_id="220726"><math alttext="Y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi></semantics></math></span> commute and <span class="math-container" id="1978548" visual_id="482833"><math alttext="Xv=0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>X</mi><mo>⁢</mo><mi>v</mi></mrow><mo>=</mo><mn>0</mn></mrow></semantics></math></span>, then <span class="math-container" id="1978549" visual_id="7613443"><math alttext="X(Yv)=Y(Xv)=0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>X</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>Y</mi><mo>⁢</mo><mi>v</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>Y</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>X</mi><mo>⁢</mo><mi>v</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow></semantics></math></span>), but also that the generalized eigenspace <span class="math-container" id="1978550" visual_id="7613444"><math alttext="\bigcup_{k}\ker(\lambda I-A)^{k}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo largeop="true" mathsize="160%" movablelimits="false" stretchy="false" symmetric="true">⋃</mo><mi>k</mi></munder><mi>ker</mi><msup><mrow><mo stretchy="false">(</mo><mi>λ</mi><mi>I</mi><mo>-</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><mi>k</mi></msup></mrow></semantics></math></span> is also preserved by <span class="math-container" id="1978575" visual_id="599"><math alttext="B" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi></semantics></math></span>.  Because of this, you can decompose your vector space <span class="math-container" id="1978552" visual_id="25"><math alttext="V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi></semantics></math></span> into joint eigenspaces <span class="math-container" id="1978553" visual_id="7613445"><math alttext="V_{\lambda\mu}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>V</mi><mrow><mi>λ</mi><mo>⁢</mo><mi>μ</mi></mrow></msub></semantics></math></span> where everything is a generalized <span class="math-container" id="1978621" visual_id="188"><math alttext="A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi></semantics></math></span>-eigenvector of eigenvalue <span class="math-container" id="1978555" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span> and a generalized <span class="math-container" id="1978575" visual_id="599"><math alttext="B" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi></semantics></math></span>-eigenvector of eigenvalue <span class="math-container" id="1978557" visual_id="375"><math alttext="\mu" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>μ</mi></semantics></math></span>.  From there it is a bit messy. </td></tr><tr><td comment_id="392275"> @chaohuang: (continued) However, this is enough to imply that if <span class="math-container" id="1978621" visual_id="188"><math alttext="A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi></semantics></math></span> is diagonalizable with no repeated eigenvalues, then any matrix commuting with <span class="math-container" id="1978621" visual_id="188"><math alttext="A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi></semantics></math></span> must also be simultaneously diagonalizable.  However, even in the <span class="math-container" id="1978560" visual_id="4582"><math alttext="2\times 2" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mn>2</mn></mrow></semantics></math></span> case, you get interesting results with repeated eigenvalues.  It's clear what commutes with the identity matrix, but what commutes with <span class="math-container" id="1978561" visual_id="6736"><math alttext="\begin{pmatrix}{1\hfil&amp;1\\ 0&amp;\end{pmatrix}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>(</mo><mi></mi><mo>)</mo></mrow></semantics></math></span>? </td></tr><tr><td comment_id="392285"> @chaohuang: (continued) The above result is also enough to show that if <span class="math-container" id="1978621" visual_id="188"><math alttext="A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi></semantics></math></span> and <span class="math-container" id="1978575" visual_id="599"><math alttext="B" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi></semantics></math></span> commute, they can be made simultaniously upper triangular, so combining this with the joint eigenspaces, the problem reduces to "Given an upper triangular matrix with either only 1's or only 0's on the diagonal, what upper triangular matrices with only 1's or only 0's on the diagonal commute with it?"  As far as I'm aware, this is a highly nontrivial problem, although there are nice results about the double commutants of collections of matrices. </td></tr><tr><td comment_id="393539"> @Aaron thanks for the clarification. </td></tr>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div class="answer">
<div answer_id="1325381" id="answer">
<p>All cyclic matrices of the same size n by n commute, each row is a cycle of the previous row.</p> <p>For two variables, with identity, there are three basic types.</p> <p>Complex or Elliptic</p> <p>x    y</p> <p>-y   x</p> <p>Dual (the ring of dual numbers)</p> <p>x  y</p> <p>0  x</p> <p>Hyperbolic (also cyclic)</p> <p>x  y</p> <p>y  x</p> <p>Each can be represented also as a "commutative ring number" x+ty for tt=-1,0,1 respectively...associated with their eigenvalues.</p>
</div>
<hr/>
<div id="answer-comments">
<table>
<tbody>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div id="duplicate">
<table>
<tbody>
<tr><td post_id="1406639"> matrix multiplication questions </td></tr><tr><td post_id="1912853"> If AB = BA, what shape must A and B have? Assume A and B are matrices. </td></tr><tr><td post_id="2566559"> Prove that for the <span class="math-container" id="23725931" visual_id="28739"><math alttext="\mathbb{R}^{n\times n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ℝ</mi><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow></msup></semantics></math></span> vector space doesn't exist a basis from <span class="math-container" id="23725932" visual_id="3802"><math alttext="n^{2}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>n</mi><mn>2</mn></msup></semantics></math></span> matrices, such that AB=BA for every two matrices in base. </td></tr><tr><td post_id="2699672"> When are two matrices A and B: AB = BA? </td></tr>
</tbody>
</table>
</div>
<hr/>
<div id="related">
<table>
<tbody>
<tr><td post_id="92480"> Given a matrix, is there always another matrix which commutes with it? </td></tr><tr><td post_id="142967"> A be a <span class="math-container" id="1659899" visual_id="2507"><math alttext="3\times 3" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow></semantics></math></span> matrix over <span class="math-container" id="1659900" visual_id="448"><math alttext="\mathbb{R}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ℝ</mi></semantics></math></span> such that <span class="math-container" id="1659901" visual_id="5084"><math alttext="AB=BA" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>A</mi><mo>⁢</mo><mi>B</mi></mrow><mo>=</mo><mrow><mi>B</mi><mo>⁢</mo><mi>A</mi></mrow></mrow></semantics></math></span> for all matrices <span class="math-container" id="1659902" visual_id="599"><math alttext="B" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi></semantics></math></span>. what can we say about such matrix <span class="math-container" id="1659903" visual_id="188"><math alttext="A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi></semantics></math></span> </td></tr><tr><td post_id="172272"> Given a matrix A, how to find  B such that AB=BA </td></tr><tr><td post_id="236212"> Prove that simultaneously diagonalizable matrices commute </td></tr><tr><td post_id="326293"> Can commuting matrices <span class="math-container" id="3521693" visual_id="9515"><math alttext="X,Y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>,</mo><mi>Y</mi></mrow></semantics></math></span> always be written as polynomials of some matrix <span class="math-container" id="3521694" visual_id="188"><math alttext="A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi></semantics></math></span>? </td></tr><tr><td post_id="938020"> commutative matrix multiplication of nxn matrices? </td></tr><tr><td post_id="1018106"> When do two <span class="math-container" id="9683540" visual_id="189"><math alttext="n\times n" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow></semantics></math></span> matrices <span class="math-container" id="9683541" visual_id="4205"><math alttext="A,B" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>,</mo><mi>B</mi></mrow></semantics></math></span> have the property that <span class="math-container" id="9683542" visual_id="5084"><math alttext="AB=BA" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>A</mi><mo>⁢</mo><mi>B</mi></mrow><mo>=</mo><mrow><mi>B</mi><mo>⁢</mo><mi>A</mi></mrow></mrow></semantics></math></span>? </td></tr><tr><td post_id="1150806"> Find if two matrices are commutative </td></tr><tr><td post_id="1464012"> How can we write examples of commutative and anticommutative matrices? </td></tr><tr><td post_id="1530918"> matrix * its inverse and AB=BA? </td></tr><tr><td post_id="1783111"> Necessary condition for matrix multiplication commutative (and if for permutation matrix) </td></tr><tr><td post_id="1927355"> Find matrices A and B such that <span class="math-container" id="17868808" visual_id="4966241"><math alttext="A^{2}*B^{2}\neq(AB)^{2}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msup><mi>A</mi><mn>2</mn></msup><mo>*</mo><msup><mi>B</mi><mn>2</mn></msup></mrow><mo>≠</mo><msup><mrow><mo stretchy="false">(</mo><mrow><mi>A</mi><mo>⁢</mo><mi>B</mi></mrow><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></mrow></semantics></math></span> </td></tr><tr><td post_id="2080245"> Constructing two matrices that do not commute </td></tr><tr><td post_id="2146477"> <span class="math-container" id="19837815" visual_id="6381197"><math alttext="vv^{T}A-Avv^{T}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>v</mi><mo>⁢</mo><msup><mi>v</mi><mi>T</mi></msup><mo>⁢</mo><mi>A</mi></mrow><mo>-</mo><mrow><mi>A</mi><mo>⁢</mo><mi>v</mi><mo>⁢</mo><msup><mi>v</mi><mi>T</mi></msup></mrow></mrow></semantics></math></span> where <span class="math-container" id="19837816" visual_id="188"><math alttext="A" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi></semantics></math></span> is skew-symmetric and <span class="math-container" id="19837817" visual_id="337150"><math alttext="vv^{T}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mo>⁢</mo><msup><mi>v</mi><mi>T</mi></msup></mrow></semantics></math></span> is rank one </td></tr><tr><td post_id="2320510"> Algebraic Rules for Matrix Equations </td></tr><tr><td post_id="2520448"> Give two examples of a non-zero matrix <span class="math-container" id="23308599" visual_id="25374"><math alttext="\textbf{A}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtext>𝐀</mtext></semantics></math></span> such that <span class="math-container" id="23308600" visual_id="1352813"><math alttext="\textbf{AX}=\textbf{XA}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>𝐀𝐗</mtext><mo>=</mo><mtext>𝐗𝐀</mtext></mrow></semantics></math></span> </td></tr><tr><td post_id="2652675"> Matrices - inverse matrices </td></tr>
</tbody>
</table>
</div>
</div>
</div>
</body>
</html>
