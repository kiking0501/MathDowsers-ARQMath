<!DOCTYPE html>

<html>
<head>
<title>What exactly is a matrix?</title>
<link href="https://cdn.sstatic.net/Shared/stacks.css?v=079c5e1603be" rel="stylesheet" type="text/css"/>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript"> </script>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap.min.css" rel="stylesheet"/>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap-theme.min.css" rel="stylesheet"/>
<style>
        .row {
          display: block;
          margin-left: auto;
          margin-right: auto;
          width:50%;
        }
        tr {
          border:1px solid lightgrey;
        }
        </style>
</head>
<body>
<div>
<div class="row" id="question-title">
<h1> What exactly is a matrix? </h1>
<hr/>
</div>
<div class="row">
<div class="question">
<div id="question" question_id="2782717">
<p>I know how basic operations are performed on matrices, I can do transformations, find inverses, etc. But now that I think about it, I actually don't "understand" or know what I've been doing all this time. Our teacher made us memorise some rules and I've been following it like a machine.</p> <ol> <li><p>So what exactly is a matrix? And what is a determinant? </p></li> <li><p>What do they represent? </p></li> <li><p>Is there a geometrical interpretation?</p></li> <li><p>How are they used? Or, rather, what for are they used?</p></li> <li><p>How do I understand the "properties" of matrix?</p></li> </ol> <p>I just don't wanna mindlessly cram all those properties, I want to understand them better. </p> <p>Any links, which would improve my understanding towards determinants and matrices? Please use simpler words. Thanks :)</p>
</div>
<hr/>
<div id="tags">
<span> linear-algebra </span><span> matrices </span><span> soft-question </span>
</div>
<hr/>
<div id="question-comments">
<table>
<tbody>
<tr><td comment_id="5738523"> Are you familiar with vectors? </td></tr><tr><td comment_id="5738529"> Matrices represent linear maps. </td></tr><tr><td comment_id="5738531"> @Michael Hoppe Yes! Infact I understand other 3D space chapters also. </td></tr><tr><td comment_id="5738533"> <span class="math-container" id="25675170" visual_id="787"><math alttext="m\times n" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></semantics></math></span> matrices can be thought of as representations of linear transformations from <span class="math-container" id="25675171" visual_id="1662"><math alttext="\mathbb{R}^{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ℝ</mi><mi>n</mi></msup></semantics></math></span> to <span class="math-container" id="25675172" visual_id="2631"><math alttext="\mathbb{R}^{m}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>ℝ</mi><mi>m</mi></msup></semantics></math></span>.  Multiplication of matrices corresponds to compositions of those linear transformations.  Determinants are useful identifiers of square matrices and have various practical applications, for example in determining whether a matrix is invertible or not. </td></tr><tr><td comment_id="5738538"> I'd recommend  3Blue1Browns [essence of linear algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) playlist. It is really good and is very intuitive. It also answers all the questions you have. It is binge watchable and quite interesting </td></tr><tr><td comment_id="5738548"> That is actually a lot of questions that might need thorough research for complete answers but as Lord Shark noticed, many things are explained by the *linear algebra* point of view (especially the multiplication). If you see a matrix as a set of vectors (its columns) then the **determinant is the volume** that is "defined" by those vectors. They are used to solve linear algebra problems (among many, many other things) because it is just more convenient some times. </td></tr><tr><td comment_id="5738569"> The best way to understand the matrices is to relate them to the linear transformations and the determinant to the linear independence of the vectors. </td></tr><tr><td comment_id="5738639"> Have you looked at these popular posts: https://math.stackexchange.com/q/668/321264, https://math.stackexchange.com/q/250534/321264 ? </td></tr><tr><td comment_id="5739110"> Professors who teach matrices as grids of numbers on which we define an arbitrary operation which for some reason is called "multiplication", rather than as representations of functions, should be tried in the Hague. I've never understood why so many (read: more than zero) books and lecture notes exist explaining the topic from that point of view. </td></tr><tr><td comment_id="5739375"> Unfortunately no one can be told what a matrix is.  You have to see it for yourself. </td></tr><tr><td comment_id="5739544"> It's already been mentioned, but OP, I highly recommend [3B1B's series](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab). In fact, I should finish watching it later today... </td></tr><tr><td comment_id="5740165"> In general, mathematics isn't concerned with what things _are_, but with what they _do_. For example, it doesn't matter if real numbers "are" Dedekind cuts or equivalence classes of Cauchy sequences. What matters is that they are an ordered field, have the least upper bound property and so on. As for matrices, the most important thing to know is that finite-dimensional linear transformations can be represented as matrices, and composition of transformations corresponds to matrix multiplication. </td></tr><tr><td comment_id="5740169"> I like to think of the determinant as a quantity that describes both the magnitude of a matrix's elements and the degree of linear independence between its rows (or columns). A matrix with rows that are "almost" dependent will have a small determinant, and a matrix with rows that are truly dependent will have a 0 determinant. </td></tr><tr><td comment_id="5744023"> Related:https://math.stackexchange.com/questions/1811886/what-is-the-most-rigorous-definition-of-a-matrix. </td></tr>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div class="answer">
<div answer_id="2783316" id="answer">
<p><strong>1. Definition of a matrix.</strong></p> <p>The question of what a matrix <em>is</em>, precisely, is one I had for a long time as a high school student.  It took many tries to get a straight answer, because people tend to conflate "matrix" with "linear transformation".  The two are closely related, but NOT the same thing.  So let me start with the fully rigorous definition of a matrix:  </p> <blockquote> <p>An <span class="math-container" id="25675173" visual_id="20"><math alttext="m" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi></semantics></math></span> by <span class="math-container" id="25675174" visual_id="177"><math alttext="n" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi></semantics></math></span> matrix is a function of two variables, the first of which has domain <span class="math-container" id="25675175" visual_id="37470"><math alttext="\{1,2,\dots,m\}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><mi>m</mi><mo stretchy="false">}</mo></mrow></semantics></math></span> and the second of which has domain <span class="math-container" id="25675176" visual_id="11011"><math alttext="\{1,2,\dots,n\}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><mi>n</mi><mo stretchy="false">}</mo></mrow></semantics></math></span>.</p> </blockquote> <p>This is the formal definition of matrices, but it's not how we usually think about them.  We have a special notation for matrices--the "box of numbers" you are familiar with, where the value of the function at <span class="math-container" id="25675177" visual_id="935"><math alttext="(1,1)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></semantics></math></span> is put in the top left corner, the value at <span class="math-container" id="25675178" visual_id="65888"><math alttext="(2,1)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>2</mn><mo>,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></semantics></math></span> is put just below it, etc.  We usually think of the matrix as just this box, and forget that it is a function.  However, sometimes you need to remember that a matrix has a more formal definition, like when implementing matrices on a computer (most programming languages have matrices built into them).</p> <p><strong>2. What matrices represent.</strong></p> <p>Matrices can represent different things in different contexts, but there is one application that is most common.  The most common application is linear transformations (a.k.a. linear maps), but before I get into that, let me briefly mention some other applications: </p> <ul> <li>Matrices can be used to store data.  For example, images on a computer are often stored as a matrix, where the matrix's value at <span class="math-container" id="25675179" visual_id="564"><math alttext="(i,j)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></semantics></math></span> is the intensity of light on the camera pixel that is <span class="math-container" id="25675180" visual_id="9565"><math alttext="i^{th}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>i</mi><mrow><mi>t</mi><mo>⁢</mo><mi>h</mi></mrow></msup></semantics></math></span> from the top and <span class="math-container" id="25675181" visual_id="48642"><math alttext="j^{th}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>j</mi><mrow><mi>t</mi><mo>⁢</mo><mi>h</mi></mrow></msup></semantics></math></span> from the left.  </li> <li>Matrices can be used as computational tools.  For example, one way to compute the Fibonacci numbers is from powers of the matrix  <span class="math-container" id="25675182" visual_id="161078"><math alttext="M=\begin{bmatrix}1&amp;amp;1\\ 1&amp;amp;0\\ \end{bmatrix}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>=</mo><mrow><mo>[</mo><mtable columnspacing="5pt" rowspacing="0pt"><mtr><mtd columnalign="center"><mn>1</mn></mtd><mtd columnalign="center"><mrow><mrow><mi>a</mi><mo>⁢</mo><mi>m</mi><mo>⁢</mo><mi>p</mi></mrow><mo>;</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd columnalign="center"><mn>1</mn></mtd><mtd columnalign="center"><mrow><mrow><mi>a</mi><mo>⁢</mo><mi>m</mi><mo>⁢</mo><mi>p</mi></mrow><mo>;</mo><mn>0</mn></mrow></mtd></mtr></mtable><mo>]</mo></mrow></mrow></semantics></math></span> It turns out that <span class="math-container" id="25675183" visual_id="8870815"><math alttext="(M^{k})_{11}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="false">(</mo><msup><mi>M</mi><mi>k</mi></msup><mo stretchy="false">)</mo></mrow><mn>11</mn></msub></semantics></math></span> is the <span class="math-container" id="25675184" visual_id="27073"><math alttext="k^{th}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>k</mi><mrow><mi>t</mi><mo>⁢</mo><mi>h</mi></mrow></msup></semantics></math></span> Fibonacci number.</li> <li>Matrices can be used to encode some mathematical structure.  I'm going to be sort of hand-wavy about this, but an example of what I have in mind is an <a href="https://en.wikipedia.org/wiki/Adjacency_matrix" rel="noreferrer">adjacency matrix</a> for a graph or network, which tells you which nodes are connected to which.  </li> </ul> <p>So the point is that a matrix can be used for lots of things.  However, one usage prevails as most common, and that is representing <strong>linear transformations</strong>.  The prevalence of this usage is why people often conflate the two concepts.  A linear transformation is a function <span class="math-container" id="25675185" visual_id="1"><math alttext="f" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi></semantics></math></span> of vectors which has the following properties:</p> <ul> <li><span class="math-container" id="25675186" visual_id="10751"><math alttext="f(x+y)=f(x)+f(y)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>x</mi><mo>+</mo><mi>y</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mrow><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></semantics></math></span> for any vectors <span class="math-container" id="25675187" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span> and <span class="math-container" id="25675188" visual_id="68"><math alttext="y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi></semantics></math></span>.</li> <li><span class="math-container" id="25675189" visual_id="50973"><math alttext="f(ax)=af(x)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mi>a</mi><mo>⁢</mo><mi>x</mi></mrow><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mi>a</mi><mo>⁢</mo><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></semantics></math></span> for any vector <span class="math-container" id="25675190" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span> and any scalar <span class="math-container" id="25675191" visual_id="159"><math alttext="a" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi></semantics></math></span>. </li> </ul> <p>These properties are what it takes to ensure that the function <span class="math-container" id="25675192" visual_id="1"><math alttext="f" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi></semantics></math></span> has "no curvature".  So it's like a straight line, but possibly in higher dimensions.  </p> <p>The relationship between matrices and linear transformations comes from the fact that a linear transformation is completely specified by the values it takes on a <em>basis</em> for its domain.  (I presume you know what a basis is.)  To see how this works, suppose we have a linear transformation <span class="math-container" id="25675193" visual_id="1"><math alttext="f" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi></semantics></math></span> which has domain <span class="math-container" id="25675194" visual_id="25"><math alttext="V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi></semantics></math></span> and range <span class="math-container" id="25675195" visual_id="304"><math alttext="W" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi></semantics></math></span>, where <span class="math-container" id="25675196" visual_id="25"><math alttext="V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi></semantics></math></span> is a vector space with basis <span class="math-container" id="25675197" visual_id="10802"><math alttext="v_{1},v_{2},\dots,v_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub><mo>,</mo><msub><mi>v</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>v</mi><mi>n</mi></msub></mrow></semantics></math></span> and <span class="math-container" id="25675198" visual_id="304"><math alttext="W" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi></semantics></math></span> is a vector space with basis <span class="math-container" id="25675199" visual_id="1635065"><math alttext="w_{1},w_{2},\dots,w_{m}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><msub><mi>w</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>w</mi><mi>m</mi></msub></mrow></semantics></math></span>.  Then there is a matrix <span class="math-container" id="25675200" visual_id="4"><math alttext="M" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi></semantics></math></span> representing <span class="math-container" id="25675201" visual_id="1"><math alttext="f" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi></semantics></math></span> <strong>with respect to these bases</strong>, which has as element <span class="math-container" id="25675202" visual_id="564"><math alttext="(i,j)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></semantics></math></span> the coefficient of <span class="math-container" id="25675203" visual_id="14848"><math alttext="w_{i}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mi>i</mi></msub></semantics></math></span> when you express <span class="math-container" id="25675204" visual_id="547785"><math alttext="f(v_{j})" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><msub><mi>v</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> as a sum of basis elements in <span class="math-container" id="25675205" visual_id="304"><math alttext="W" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi></semantics></math></span>.  </p> <p>The reason that this is a good idea is that if you have some miscellaneous vector <span class="math-container" id="25675206" visual_id="8870816"><math alttext="x=a_{1}v_{1}+a_{2}v_{2}+\cdots+a_{n}v_{n}\in V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mrow><mrow><msub><mi>a</mi><mn>1</mn></msub><mo>⁢</mo><msub><mi>v</mi><mn>1</mn></msub></mrow><mo>+</mo><mrow><msub><mi>a</mi><mn>2</mn></msub><mo>⁢</mo><msub><mi>v</mi><mn>2</mn></msub></mrow><mo>+</mo><mi mathvariant="normal">⋯</mi><mo>+</mo><mrow><msub><mi>a</mi><mi>n</mi></msub><mo>⁢</mo><msub><mi>v</mi><mi>n</mi></msub></mrow></mrow><mo>∈</mo><mi>V</mi></mrow></semantics></math></span>, then if you represent <span class="math-container" id="25675207" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span> as a column vector <span class="math-container" id="25675208" visual_id="8870817"><math alttext="[a_{1},a_{2},\dots,a_{n}]^{T}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mrow><mo stretchy="false">[</mo><msub><mi>a</mi><mn>1</mn></msub><mo>,</mo><msub><mi>a</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>a</mi><mi>n</mi></msub><mo stretchy="false">]</mo></mrow><mi>T</mi></msup></semantics></math></span> and <span class="math-container" id="25675209" visual_id="1"><math alttext="f" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi></semantics></math></span> as its matrix <span class="math-container" id="25675210" visual_id="4"><math alttext="M" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi></semantics></math></span>, then the value <span class="math-container" id="25675211" visual_id="1805"><math alttext="f(x)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> is given by the matrix product of <span class="math-container" id="25675212" visual_id="4"><math alttext="M" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi></semantics></math></span> and <span class="math-container" id="25675213" visual_id="8870817"><math alttext="[a_{1},a_{2},\dots,a_{n}]^{T}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mrow><mo stretchy="false">[</mo><msub><mi>a</mi><mn>1</mn></msub><mo>,</mo><msub><mi>a</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>a</mi><mi>n</mi></msub><mo stretchy="false">]</mo></mrow><mi>T</mi></msup></semantics></math></span>.  So the matrix <span class="math-container" id="25675214" visual_id="4"><math alttext="M" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi></semantics></math></span> completely encodes the linear transformation <span class="math-container" id="25675215" visual_id="1"><math alttext="f" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi></semantics></math></span>, and matrix multiplication tells you how to decode it, i.e. how to use the matrix to get values of <span class="math-container" id="25675216" visual_id="1"><math alttext="f" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi></semantics></math></span>.  </p> <p><strong>3. Geometrical intuition.</strong></p> <p>In my opinion, the most important theorem for getting intuition for matrices and linear transformations is the <a href="https://en.wikipedia.org/wiki/Singular-value_decomposition" rel="noreferrer">singular value decomposition</a> theorem.  This says that any linear transformation can be written as a sequence of three simple transformations: a rotation, a stretching, and another rotation.  Note that the stretching operation can stretch by different amounts in different orthogonal directions.  This tells you that all linear transformations are some combination of rotation and stretching.  </p> <p>Other properties of matrices often have direct geometric interpretation, too.  For example, the determinant tells you how a linear transformation changes volumes.  By the singular value decomposition, a linear transformation turns a cube into some sort of stretched and rotated parallelogram.  The determinant is the ratio of the volume of the resulting parallelogram to that of the cube you started with.  </p> <p>Not all properties of a matrix can be easily associated with familiar geometric concepts, though.  I don't know of a good geometric picture for the trace, for instance.  That doesn't mean that the trace is any less useful or easy to work with, though!</p> <p><strong>4. Other properties.</strong></p> <p>Almost all of the "properties" and "operations" for matrices come from properties of linear maps and theorems about them.  For example, the standard multiplication of matrices is designed specifically to give the values of linear maps as explained above.  This is NOT the only type of multiplication that can be defined on matrices, and in fact there are other types of multiplication for matrices (for example, the <a href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)" rel="noreferrer">Hadamard product</a> and the <a href="https://en.wikipedia.org/wiki/Kronecker_product" rel="noreferrer">Kronecker product</a>).  These other types of multiplication are sometimes useful, but generally not as useful as regular matrix multiplication, so people often don't know (or care) about them.</p> <hr/> <p><strong>5. TL;DR</strong></p> <p>The moral of the story is that you can use matrices for whatever you want (and they are indeed used in many different ways), but the way that most people use them most of the time is to represent linear maps, and the standard definitions and "properties" of matrices reflect this bias.  The study of linear maps goes by the name "linear algebra", and a textbook on this subject is a good place to start if you want to learn more about matrices.  (Depending on your background, you may find some good reference suggestions here: <a href="https://math.stackexchange.com/questions/2402775/looking-for-a-rigorous-linear-algebra-book">link</a>.)</p>
</div>
<hr/>
<div id="answer-comments">
<table>
<tbody>
<tr><td comment_id="5740654"> A similar way to look at the essential characteristic of what a matrix itself is, is to define it as an ordered <span class="math-container" id="25675217" visual_id="15627"><math alttext="n\times m" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>×</mo><mi>m</mi></mrow></semantics></math></span>-tuple, that is usually written out in a grid format rather than in a list format, like a vector. </td></tr><tr><td comment_id="5742683"> Good answer, but I would put the summary at the beginning — especially if you call it _Too Long; Did not Read_! </td></tr><tr><td comment_id="5750644"> Although it's techincally correct that matrices and maps are not the same thing, for the (frequent) case of <span class="math-container" id="25675218" visual_id="8870818"><math alttext="f:\mathbb{K}^{n}\rightarrow\mathbb{K}^{m}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>:</mo><mrow><msup><mi>𝕂</mi><mi>n</mi></msup><mo>→</mo><msup><mi>𝕂</mi><mi>m</mi></msup></mrow></mrow></semantics></math></span> with respect to the standard basis, we have a one-to-one connection between those concepts (even more: we have an isomorphism between categories), and so it's useful to just identify both. The same thing is done e.g. in differential geometry, where we have three definitions for the tangent bundle (equivalent curves, vectors in each chart, and abstract derivations) and don't explicitly write an isomorphism each time. </td></tr>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div id="duplicate">
<table>
<tbody>
</tbody>
</table>
</div>
<hr/>
<div id="related">
<table>
<tbody>
<tr><td post_id="250534"> Geometric meaning of the determinant of a matrix </td></tr><tr><td post_id="668"> What's an intuitive way to think about the determinant? </td></tr><tr><td post_id="1811886"> What is the most rigorous definition of a matrix? </td></tr><tr><td post_id="2402775"> Looking for a rigorous linear algebra book </td></tr>
</tbody>
</table>
</div>
</div>
</div>
</body>
</html>
