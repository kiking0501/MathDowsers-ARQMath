<!DOCTYPE html>

<html>
<head>
<title>Countably dimensional vector space as a limit</title>
<link href="https://cdn.sstatic.net/Shared/stacks.css?v=079c5e1603be" rel="stylesheet" type="text/css"/>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript"> </script>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap.min.css" rel="stylesheet"/>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap-theme.min.css" rel="stylesheet"/>
<style>
        .row {
          display: block;
          margin-left: auto;
          margin-right: auto;
          width:50%;
        }
        tr {
          border:1px solid lightgrey;
        }
        </style>
</head>
<body>
<div>
<div class="row" id="question-title">
<h1> Countably dimensional vector space as a limit </h1>
<hr/>
</div>
<div class="row">
<div class="question">
<div id="question" question_id="1953021">
<p>Consider for example the countable product of <span class="math-container" id="18103112" visual_id="342"><math alttext="1" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn></semantics></math></span>-dimensional vector spaces <span class="math-container" id="18103113" visual_id="5042319"><math alttext="V:=\prod_{n\geq 0}k\cdot e_{n}," class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>V</mi><mo>:=</mo><mrow><msub><mo largeop="true" symmetric="true">∏</mo><mrow><mi>n</mi><mo>≥</mo><mn>0</mn></mrow></msub><mrow><mi>k</mi><mo>⋅</mo><msub><mi>e</mi><mi>n</mi></msub></mrow></mrow></mrow><mo>,</mo></mrow></semantics></math></span> <span class="math-container" id="18103114" visual_id="83"><math alttext="k" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi></semantics></math></span> a field. This space is of uncountable dimension: if <span class="math-container" id="18103115" visual_id="416052"><math alttext="\{v_{1},v_{2},\ldots\}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>v</mi><mn>1</mn></msub><mo>,</mo><msub><mi>v</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo stretchy="false">}</mo></mrow></semantics></math></span> were a countable basis, let <span class="math-container" id="18103116" visual_id="5042320"><math alttext="v_{n,j}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>v</mi><mrow><mi>n</mi><mo>,</mo><mi>j</mi></mrow></msub></semantics></math></span> denote the coordinates of <span class="math-container" id="18103117" visual_id="14610"><math alttext="v_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>v</mi><mi>n</mi></msub></semantics></math></span>, that is <span class="math-container" id="18103118" visual_id="5042321"><math alttext="v_{n}=\sum_{j\geq 1}v_{n,j}e_{j}." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>v</mi><mi>n</mi></msub><mo>=</mo><mrow><msub><mo largeop="true" symmetric="true">∑</mo><mrow><mi>j</mi><mo>≥</mo><mn>1</mn></mrow></msub><mrow><msub><mi>v</mi><mrow><mi>n</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>⁢</mo><msub><mi>e</mi><mi>j</mi></msub></mrow></mrow></mrow><mo>.</mo></mrow></semantics></math></span> By swapping elements and using finite linear combinations <em>à la</em> Gauss, we can assume without loss of generality that <span class="math-container" id="18103119" visual_id="4099115"><math alttext="v_{i,j}=0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn></mrow></semantics></math></span> for all <span class="math-container" id="18103120" visual_id="82495"><math alttext="j&amp;lt;i" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>j</mi><mo>&lt;</mo></mrow><mi>i</mi></mrow></semantics></math></span>. Now consider <span class="math-container" id="18103121" visual_id="5042322"><math alttext="v:=\sum_{n\geq 0}\left(\sum_{j=0}^{n}v_{n,j}\right)e_{n}\in V." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>v</mi><mo>:=</mo><mrow><msub><mo largeop="true" symmetric="true">∑</mo><mrow><mi>n</mi><mo>≥</mo><mn>0</mn></mrow></msub><mrow><mrow><mo>(</mo><mrow><msubsup><mo largeop="true" symmetric="true">∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></msubsup><msub><mi>v</mi><mrow><mi>n</mi><mo>,</mo><mi>j</mi></mrow></msub></mrow><mo>)</mo></mrow><mo>⁢</mo><msub><mi>e</mi><mi>n</mi></msub></mrow></mrow><mo>∈</mo><mi>V</mi></mrow><mo>.</mo></mrow></semantics></math></span> It is clear that <span class="math-container" id="18103122" visual_id="1546"><math alttext="v" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>v</mi></semantics></math></span> cannot be written as a finite linear combination of element of the chosen set of elements.</p> <p>My question is:</p> <blockquote> <p>Can one obtain a countably dimensional vector space as an arbitrary (category theoretical) limit of finite dimensional spaces? For example as the kernel of some linear map?</p> <p>If not, how can one prove it?</p> </blockquote>
</div>
<hr/>
<div id="tags">
<span> linear-algebra </span><span> vector-spaces </span><span> category-theory </span><span> limits-colimits </span>
</div>
<hr/>
<div id="question-comments">
<table>
<tbody>
<tr><td comment_id="4009514"> You have proven that <span class="math-container" id="18103123" visual_id="53005"><math alttext="|V|" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow></semantics></math></span> is uncountable, but so is <span class="math-container" id="18103124" visual_id="448"><math alttext="\mathbb{R}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ℝ</mi></semantics></math></span>, so this does not prove that <span class="math-container" id="18103245" visual_id="25"><math alttext="V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi></semantics></math></span> is uncountably dimensional.  If our definition of the product topology requires finite sums of basis vectors you are correct.  If we allow infinite sums of basis vectors the space has countable dimension. </td></tr><tr><td comment_id="4009527"> @RossMillikan I don't think I understand your remark... I am working in the category of vector spaces, so I'm not considering any topology. Also, I work with Hamel bases, so I only allow finite sums of basis vectors. </td></tr><tr><td comment_id="4009538"> If you only allow finite sums you are correct, but the cardinality of the space is not sufficient.  You  can multiply each basis vector by uncountably many coefficients so the space is uncountable.  That would also  be true for a finite dimensional space.  You are claiming that countably many vectors cannot span the space. </td></tr><tr><td comment_id="4009553"> @RossMillikan Ah, I see. The sequences I consider are not linearly independent. But still, I'm pretty convinced that the space we obtain that way is uncountably dimensional. I'll think about a proof of that fact. </td></tr><tr><td comment_id="4010110"> @RossMillikan Ok, *now* I have proven that the space <span class="math-container" id="18103245" visual_id="25"><math alttext="V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi></semantics></math></span> has uncountable dimension. </td></tr>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div class="answer">
<div answer_id="1953100" id="answer">
<p>Let me begin with two Lemmas.</p> <blockquote> <p><strong>Lemma 1</strong>: Let <span class="math-container" id="18103133" visual_id="1003874"><math alttext="(X_{\alpha})" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>X</mi><mi>α</mi></msub><mo stretchy="false">)</mo></mrow></semantics></math></span> be an inverse system of compact <span class="math-container" id="18103134" visual_id="28987"><math alttext="T_{0}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>T</mi><mn>0</mn></msub></semantics></math></span> spaces such that the maps of the system are all closed maps.  Then the inverse limit <span class="math-container" id="18103135" visual_id="1808919"><math alttext="X=\varprojlim X_{\alpha}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mrow><munder accentunder="true"><mi>lim</mi><mo>←</mo></munder><mo>⁡</mo><msub><mi>X</mi><mi>α</mi></msub></mrow></mrow></semantics></math></span> is compact.</p> </blockquote> <p><em>Proof</em>: See <a href="http://www.sciencedirect.com/science/article/pii/0016660X79900084" rel="nofollow noreferrer">A.H. Stone, Inverse limits of compact spaces, General Topology and its Applications (1979)</a>, Theorem 5.</p> <blockquote> <p><strong>Lemma 2</strong>: Let <span class="math-container" id="18103136" visual_id="21968"><math alttext="(V_{i})_{i\in I}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="false">(</mo><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>i</mi><mo>∈</mo><mi>I</mi></mrow></msub></semantics></math></span> be a family of vector spaces and suppose <span class="math-container" id="18103137" visual_id="5042326"><math alttext="x_{1},\dots,x_{n}\in\prod_{i\in I}V_{i}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow><mo>∈</mo><mrow><msub><mo largeop="true" symmetric="true">∏</mo><mrow><mi>i</mi><mo>∈</mo><mi>I</mi></mrow></msub><msub><mi>V</mi><mi>i</mi></msub></mrow></mrow></semantics></math></span> are linearly independent.  Then there exists a finite subset <span class="math-container" id="18103138" visual_id="1250026"><math alttext="S\subseteq I" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>⊆</mo><mi>I</mi></mrow></semantics></math></span> such that the images of <span class="math-container" id="18103139" visual_id="7647"><math alttext="x_{1},\dots,x_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></semantics></math></span> in <span class="math-container" id="18103140" visual_id="5042327"><math alttext="\prod_{i\in S}V_{i}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo largeop="true" symmetric="true">∏</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi></mrow></msub><msub><mi>V</mi><mi>i</mi></msub></mrow></semantics></math></span> are still linearly independent.</p> </blockquote> <p><em>Proof</em>: We use induction on <span class="math-container" id="18103141" visual_id="177"><math alttext="n" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi></semantics></math></span>; the case <span class="math-container" id="18103142" visual_id="3350"><math alttext="n=0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>0</mn></mrow></semantics></math></span> is trivial.  Given a subset <span class="math-container" id="18103143" visual_id="1250026"><math alttext="S\subseteq I" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>⊆</mo><mi>I</mi></mrow></semantics></math></span>,  we say that a statement about elements of <span class="math-container" id="18103144" visual_id="2660943"><math alttext="\prod_{i\in I}V_{i}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo largeop="true" symmetric="true">∏</mo><mrow><mi>i</mi><mo>∈</mo><mi>I</mi></mrow></msub><msub><mi>V</mi><mi>i</mi></msub></mrow></semantics></math></span> is true "over <span class="math-container" id="18103145" visual_id="403"><math alttext="S" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi></semantics></math></span>" if it is true when you project everything to <span class="math-container" id="18103146" visual_id="5042327"><math alttext="\prod_{i\in S}V_{i}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo largeop="true" symmetric="true">∏</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi></mrow></msub><msub><mi>V</mi><mi>i</mi></msub></mrow></semantics></math></span>.</p> <p>Suppose the Lemma is true for <span class="math-container" id="18103147" visual_id="177"><math alttext="n" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi></semantics></math></span> and let <span class="math-container" id="18103148" visual_id="5042328"><math alttext="x_{1},\dots,x_{n+1}\in\prod_{i\in I}V_{i}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><mo>∈</mo><mrow><msub><mo largeop="true" symmetric="true">∏</mo><mrow><mi>i</mi><mo>∈</mo><mi>I</mi></mrow></msub><msub><mi>V</mi><mi>i</mi></msub></mrow></mrow></semantics></math></span> be linearly independent.  By the induction hypothesis, we can find a finite subset <span class="math-container" id="18103149" visual_id="1250026"><math alttext="S\subseteq I" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>⊆</mo><mi>I</mi></mrow></semantics></math></span> such that <span class="math-container" id="18103150" visual_id="7647"><math alttext="x_{1},\dots,x_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></semantics></math></span> are linearly independent over <span class="math-container" id="18103151" visual_id="403"><math alttext="S" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi></semantics></math></span>.  Suppose that no finite set <span class="math-container" id="18103152" visual_id="319"><math alttext="T" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi></semantics></math></span> exists such that <span class="math-container" id="18103153" visual_id="5042329"><math alttext="x_{1},\dots x_{n+1}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mrow><mi mathvariant="normal">…</mi><mo>⁢</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></mrow></semantics></math></span> are linearly independent.  Given any finite set <span class="math-container" id="18103154" visual_id="380462"><math alttext="T\supseteq S" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>⊇</mo><mi>S</mi></mrow></semantics></math></span>, a linear relation between the <span class="math-container" id="18103155" visual_id="2893"><math alttext="x_{k}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>k</mi></msub></semantics></math></span> over <span class="math-container" id="18103156" visual_id="319"><math alttext="T" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi></semantics></math></span> must involve <span class="math-container" id="18103157" visual_id="24510"><math alttext="x_{n+1}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></semantics></math></span>, so there exist scalars <span class="math-container" id="18103158" visual_id="5042330"><math alttext="a_{1}^{T},\dots,a_{n}^{T}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>a</mi><mn>1</mn><mi>T</mi></msubsup><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msubsup><mi>a</mi><mi>n</mi><mi>T</mi></msubsup></mrow></semantics></math></span> such that <span class="math-container" id="18103159" visual_id="5042331"><math alttext="x_{n+1}=\sum_{k=1}^{n}a_{k}^{T}x_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><msubsup><mo largeop="true" symmetric="true">∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><msubsup><mi>a</mi><mi>k</mi><mi>T</mi></msubsup><mo>⁢</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></mrow></mrow></semantics></math></span> over <span class="math-container" id="18103160" visual_id="319"><math alttext="T" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi></semantics></math></span>.  Moreover, these scalars are actually unique, since <span class="math-container" id="18103161" visual_id="7647"><math alttext="x_{1},\dots,x_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></semantics></math></span> are linearly independent over <span class="math-container" id="18103162" visual_id="403"><math alttext="S" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi></semantics></math></span> (and hence also over <span class="math-container" id="18103163" visual_id="319"><math alttext="T" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi></semantics></math></span>).  This uniqueness implies that if <span class="math-container" id="18103164" visual_id="914087"><math alttext="T\subseteq T^{\prime}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>⊆</mo><msup><mi>T</mi><mo>′</mo></msup></mrow></semantics></math></span>, <span class="math-container" id="18103165" visual_id="5042332"><math alttext="a_{k}^{T}=a_{k}^{T^{\prime}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>a</mi><mi>k</mi><mi>T</mi></msubsup><mo>=</mo><msubsup><mi>a</mi><mi>k</mi><msup><mi>T</mi><mo>′</mo></msup></msubsup></mrow></semantics></math></span> for all <span class="math-container" id="18103166" visual_id="83"><math alttext="k" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi></semantics></math></span>.  This then implies that <span class="math-container" id="18103167" visual_id="1488557"><math alttext="a_{k}^{T}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>a</mi><mi>k</mi><mi>T</mi></msubsup></semantics></math></span> is independent of the choice of <span class="math-container" id="18103168" visual_id="319"><math alttext="T" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi></semantics></math></span>, since any two <span class="math-container" id="18103169" visual_id="319"><math alttext="T" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi></semantics></math></span>'s can be compared to their union.  Thus there exist scalars <span class="math-container" id="18103170" visual_id="1626"><math alttext="a_{k}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>a</mi><mi>k</mi></msub></semantics></math></span> such that <span class="math-container" id="18103171" visual_id="5042333"><math alttext="x_{n+1}=\sum_{k=1}^{n}a_{k}x_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><msubsup><mo largeop="true" symmetric="true">∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><msub><mi>a</mi><mi>k</mi></msub><mo>⁢</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></mrow></mrow></semantics></math></span> over <em>any</em> finite set <span class="math-container" id="18103172" visual_id="319"><math alttext="T" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi></semantics></math></span> containing <span class="math-container" id="18103173" visual_id="403"><math alttext="S" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi></semantics></math></span>.  This implies that actually <span class="math-container" id="18103174" visual_id="5042333"><math alttext="x_{n+1}=\sum_{k=1}^{n}a_{k}x_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mrow><msubsup><mo largeop="true" symmetric="true">∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mrow><msub><mi>a</mi><mi>k</mi></msub><mo>⁢</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></mrow></mrow></semantics></math></span> in <span class="math-container" id="18103175" visual_id="2660943"><math alttext="\prod_{i\in I}V_{i}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo largeop="true" symmetric="true">∏</mo><mrow><mi>i</mi><mo>∈</mo><mi>I</mi></mrow></msub><msub><mi>V</mi><mi>i</mi></msub></mrow></semantics></math></span>, which contradicts the assumption that <span class="math-container" id="18103176" visual_id="167347"><math alttext="x_{1},\dots,x_{n+1}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></semantics></math></span> was linearly independent.</p> <hr/> <p>Now I will prove that a countably infinite dimensional vector space cannot be a limit of finite dimensional vector spaces.  Here's the executive summary: if an infinite dimensional vector space is a limit of finite dimensional vector spaces, it is an inverse limit of finite dimensional vector spaces.  Given such an inverse limit, using Lemma 2 you can find a sequence of spaces in it whose dimension goes to infinity, and then the inverse limit of that sequence has uncountable dimension.  But by a compactness argument using Lemma 1, the inverse limit of the whole system surjects onto the inverse limit of the sequence.</p> <p>Now for the details.  Suppose <span class="math-container" id="18103177" visual_id="5042334"><math alttext="F:I\to\mathtt{Vect}_{k}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo>:</mo><mrow><mi>I</mi><mo>→</mo><msub><mi>𝚅𝚎𝚌𝚝</mi><mi>k</mi></msub></mrow></mrow></semantics></math></span> is a diagram of finite-dimensional vector-spaces whose limit <span class="math-container" id="18103178" visual_id="580"><math alttext="L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi></semantics></math></span> is infinite dimensional.  Note that <span class="math-container" id="18103179" visual_id="580"><math alttext="L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi></semantics></math></span> is naturally a subspace of the product <span class="math-container" id="18103180" visual_id="5042335"><math alttext="V=\prod_{i\in I}F(i)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mrow><msub><mo largeop="true" symmetric="true">∏</mo><mrow><mi>i</mi><mo>∈</mo><mi>I</mi></mrow></msub><mrow><mi>F</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></semantics></math></span> over all objects of <span class="math-container" id="18103181" visual_id="989"><math alttext="I" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>I</mi></semantics></math></span>.  For each finite set of objects <span class="math-container" id="18103182" visual_id="672471"><math alttext="S\subset I" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>⊂</mo><mi>I</mi></mrow></semantics></math></span>, let <span class="math-container" id="18103183" visual_id="5042336"><math alttext="V_{S}=\prod_{i\in S}F(i)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>S</mi></msub><mo>=</mo><mrow><msub><mo largeop="true" symmetric="true">∏</mo><mrow><mi>i</mi><mo>∈</mo><mi>S</mi></mrow></msub><mrow><mi>F</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></semantics></math></span>.  Give each <span class="math-container" id="18103184" visual_id="300290"><math alttext="V_{S}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>V</mi><mi>S</mi></msub></semantics></math></span> a topology by saying that a closed set is a finite union of affine subspaces of <span class="math-container" id="18103185" visual_id="300290"><math alttext="V_{S}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>V</mi><mi>S</mi></msub></semantics></math></span>.  Since <span class="math-container" id="18103186" visual_id="300290"><math alttext="V_{S}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>V</mi><mi>S</mi></msub></semantics></math></span> is finite dimensional, this topology is Noetherian, and in particular is compact.  The projection maps between the spaces <span class="math-container" id="18103187" visual_id="300290"><math alttext="V_{S}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>V</mi><mi>S</mi></msub></semantics></math></span> for different values of <span class="math-container" id="18103188" visual_id="403"><math alttext="S" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi></semantics></math></span> are also continuous and closed.  By Lemma 1, if we topologize <span class="math-container" id="18103189" visual_id="25"><math alttext="V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi></semantics></math></span> as the inverse limit of the <span class="math-container" id="18103190" visual_id="300290"><math alttext="V_{S}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>V</mi><mi>S</mi></msub></semantics></math></span>, <span class="math-container" id="18103191" visual_id="25"><math alttext="V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi></semantics></math></span> is compact.  Moreover, <span class="math-container" id="18103192" visual_id="580"><math alttext="L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi></semantics></math></span> is a closed subset of <span class="math-container" id="18103193" visual_id="25"><math alttext="V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi></semantics></math></span>, since for each morphism in <span class="math-container" id="18103194" visual_id="989"><math alttext="I" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>I</mi></semantics></math></span> the condition that an element of <span class="math-container" id="18103195" visual_id="25"><math alttext="V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi></semantics></math></span> respect that morphism defines a basic closed set in the topology of <span class="math-container" id="18103196" visual_id="25"><math alttext="V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi></semantics></math></span>.  Thus <span class="math-container" id="18103197" visual_id="580"><math alttext="L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi></semantics></math></span> is compact as well.</p> <p>Since <span class="math-container" id="18103198" visual_id="580"><math alttext="L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi></semantics></math></span> is infinite-dimensional, we can choose an infinite sequence <span class="math-container" id="18103199" visual_id="8329"><math alttext="(x_{n})_{n\in\mathbb{N}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>n</mi><mo>∈</mo><mi>ℕ</mi></mrow></msub></semantics></math></span> of linearly independent elements of <span class="math-container" id="18103200" visual_id="580"><math alttext="L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi></semantics></math></span>.  By Lemma 2, we can choose finite subsets <span class="math-container" id="18103201" visual_id="5042337"><math alttext="S_{n}\subset I" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>n</mi></msub><mo>⊂</mo><mi>I</mi></mrow></semantics></math></span> for each <span class="math-container" id="18103202" visual_id="177"><math alttext="n" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi></semantics></math></span> such that <span class="math-container" id="18103203" visual_id="7647"><math alttext="x_{1},\dots,x_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></semantics></math></span> are linearly independent when projected to <span class="math-container" id="18103204" visual_id="5042338"><math alttext="V_{S_{n}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>V</mi><msub><mi>S</mi><mi>n</mi></msub></msub></semantics></math></span>.  We may also assume that <span class="math-container" id="18103205" visual_id="1864406"><math alttext="S_{n}\subseteq S_{n+1}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>n</mi></msub><mo>⊆</mo><msub><mi>S</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></semantics></math></span> for each <span class="math-container" id="18103206" visual_id="177"><math alttext="n" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi></semantics></math></span>.</p> <p>Now let <span class="math-container" id="18103207" visual_id="54763"><math alttext="L_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>n</mi></msub></semantics></math></span> be the image of <span class="math-container" id="18103208" visual_id="580"><math alttext="L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi></semantics></math></span> in <span class="math-container" id="18103209" visual_id="5042338"><math alttext="V_{S_{n}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>V</mi><msub><mi>S</mi><mi>n</mi></msub></msub></semantics></math></span>.  By our choice of <span class="math-container" id="18103210" visual_id="4658"><math alttext="S_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>S</mi><mi>n</mi></msub></semantics></math></span>, <span class="math-container" id="18103211" visual_id="5042339"><math alttext="\dim L_{n}\geq n" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo>dim</mo><mo>⁡</mo><msub><mi>L</mi><mi>n</mi></msub></mrow><mo>≥</mo><mi>n</mi></mrow></semantics></math></span> for all <span class="math-container" id="18103212" visual_id="177"><math alttext="n" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi></semantics></math></span>.  The vector spaces <span class="math-container" id="18103213" visual_id="54763"><math alttext="L_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>n</mi></msub></semantics></math></span> naturally form an inverse system <span class="math-container" id="18103214" visual_id="5042340"><math alttext="\dots\to L_{2}\to L_{1}\to L_{0}." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">…</mi><mo>→</mo><msub><mi>L</mi><mn>2</mn></msub><mo>→</mo><msub><mi>L</mi><mn>1</mn></msub><mo>→</mo><msub><mi>L</mi><mn>0</mn></msub></mrow><mo>.</mo></mrow></semantics></math></span>  Let <span class="math-container" id="18103215" visual_id="1406889"><math alttext="L_{\omega}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>ω</mi></msub></semantics></math></span> be the inverse limit of this system.  There is a natural linear map <span class="math-container" id="18103216" visual_id="5042341"><math alttext="f:L\to L_{\omega}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>:</mo><mrow><mi>L</mi><mo>→</mo><msub><mi>L</mi><mi>ω</mi></msub></mrow></mrow></semantics></math></span>, which I claim is surjective.  Indeed, given an element <span class="math-container" id="18103217" visual_id="5042342"><math alttext="y\in L_{\omega}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>∈</mo><msub><mi>L</mi><mi>ω</mi></msub></mrow></semantics></math></span>, for each <span class="math-container" id="18103218" visual_id="177"><math alttext="n" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi></semantics></math></span> the set of <span class="math-container" id="18103219" visual_id="21201"><math alttext="x\in L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∈</mo><mi>L</mi></mrow></semantics></math></span> which agree with <span class="math-container" id="18103220" visual_id="68"><math alttext="y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi></semantics></math></span> on <span class="math-container" id="18103221" visual_id="54763"><math alttext="L_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>n</mi></msub></semantics></math></span> is a nonempty closed subset of <span class="math-container" id="18103222" visual_id="580"><math alttext="L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi></semantics></math></span>.  These closed subsets have the finite intersection property, so their intersection is nonempty by compactness of <span class="math-container" id="18103223" visual_id="580"><math alttext="L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi></semantics></math></span>.  But their intersection is just <span class="math-container" id="18103224" visual_id="49043"><math alttext="f^{-1}(\{y\})" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mo stretchy="false">{</mo><mi>y</mi><mo stretchy="false">}</mo></mrow><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span>.  Thus <span class="math-container" id="18103225" visual_id="49043"><math alttext="f^{-1}(\{y\})" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mo stretchy="false">{</mo><mi>y</mi><mo stretchy="false">}</mo></mrow><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> is nonempty for any <span class="math-container" id="18103226" visual_id="5042342"><math alttext="y\in L_{\omega}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>∈</mo><msub><mi>L</mi><mi>ω</mi></msub></mrow></semantics></math></span>, so <span class="math-container" id="18103227" visual_id="1"><math alttext="f" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>f</mi></semantics></math></span> is surjective.</p> <p>Thus to show that <span class="math-container" id="18103228" visual_id="580"><math alttext="L" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi></semantics></math></span> has uncountable dimension, it suffices to show that <span class="math-container" id="18103229" visual_id="1406889"><math alttext="L_{\omega}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>ω</mi></msub></semantics></math></span> has uncountable dimension.  But <span class="math-container" id="18103230" visual_id="1406889"><math alttext="L_{\omega}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>ω</mi></msub></semantics></math></span> is easy to understand, since the maps <span class="math-container" id="18103231" visual_id="5042343"><math alttext="L_{n+1}\to L_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>→</mo><msub><mi>L</mi><mi>n</mi></msub></mrow></semantics></math></span> are all surjective.  If <span class="math-container" id="18103232" visual_id="5042344"><math alttext="d_{n}=\dim L_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>n</mi></msub><mo>=</mo><mrow><mo>dim</mo><mo>⁡</mo><msub><mi>L</mi><mi>n</mi></msub></mrow></mrow></semantics></math></span>, we can choose bases for <span class="math-container" id="18103233" visual_id="54763"><math alttext="L_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>n</mi></msub></semantics></math></span> for each <span class="math-container" id="18103234" visual_id="177"><math alttext="n" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi></semantics></math></span> such that the map <span class="math-container" id="18103235" visual_id="5042343"><math alttext="L_{n+1}\to L_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>→</mo><msub><mi>L</mi><mi>n</mi></msub></mrow></semantics></math></span> maps the first <span class="math-container" id="18103236" visual_id="4663"><math alttext="d_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>d</mi><mi>n</mi></msub></semantics></math></span> basis vectors of <span class="math-container" id="18103237" visual_id="447054"><math alttext="L_{n+1}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></semantics></math></span> to the basis vectors of <span class="math-container" id="18103238" visual_id="54763"><math alttext="L_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>n</mi></msub></semantics></math></span> and the remaining basis vectors of <span class="math-container" id="18103239" visual_id="447054"><math alttext="L_{n+1}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></semantics></math></span> to <span class="math-container" id="18103240" visual_id="92"><math alttext="0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn></semantics></math></span>.  It is then clear that the inverse limit of this system can be identified with <span class="math-container" id="18103241" visual_id="2624984"><math alttext="k^{\mathbb{N}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>k</mi><mi>ℕ</mi></msup></semantics></math></span> (the coordinates corresponding to the coefficients with respect to our bases on the <span class="math-container" id="18103242" visual_id="54763"><math alttext="L_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>L</mi><mi>n</mi></msub></semantics></math></span>).  Since <span class="math-container" id="18103243" visual_id="2624984"><math alttext="k^{\mathbb{N}}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>k</mi><mi>ℕ</mi></msup></semantics></math></span> has uncountable dimension (see <a href="https://mathoverflow.net/a/168624/75">https://mathoverflow.net/a/168624/75</a>, for instance), we're done.</p>
</div>
<hr/>
<div id="answer-comments">
<table>
<tbody>
<tr><td comment_id="4009815"> You might be tempted to avoid the use of Lemma 1 by just putting the Zariski topology on each <span class="math-container" id="18103244" visual_id="300290"><math alttext="V_{S}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>V</mi><mi>S</mi></msub></semantics></math></span>, so that the inverse limit topology on <span class="math-container" id="18103245" visual_id="25"><math alttext="V" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi></semantics></math></span> is just the Zariski topology on (the <span class="math-container" id="18103247" visual_id="83"><math alttext="k" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi></semantics></math></span>-points of) an infinite-dimensional affine space, and then you can make an algebraic argument that this is compact.  However, it turns out that the Zariski topology on the <span class="math-container" id="18103247" visual_id="83"><math alttext="k" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi></semantics></math></span>-points of an infinite-dimensional affine space is actually not compact in general!  Note that Lemma 1 does not apply to the Zariski topology, since projections between affine spaces are not closed maps. </td></tr><tr><td comment_id="4010113"> Thanks a lot for the answer! The solution is a lot more convoluted than I thought. It's a nice interplay between linear algebra and topology, but as topology is used as an auxiliary tool, I wonder if there is a more elementary proof somewhere. </td></tr><tr><td comment_id="4010121"> Also, a minor remark: in the proof of Lemma 2, it should be "Then given any finite set <span class="math-container" id="18103253" visual_id="380462"><math alttext="T\supseteq S" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>⊇</mo><mi>S</mi></mrow></semantics></math></span> **such that <span class="math-container" id="18103249" visual_id="167347"><math alttext="x_{1},\ldots,x_{n+1}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></semantics></math></span> are linearly independent over <span class="math-container" id="18103255" visual_id="319"><math alttext="T" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi></semantics></math></span>** (...)" I think. </td></tr><tr><td comment_id="4010627"> (1) Yeah, the proof was more complicated than I wanted it to be too...I think that this result really is a "compactness" result in an essential way, so even if you don't use the topological setup you will still be making similar sorts of arguments.  But I would expect/hope that there is a simpler way to set it all up (in particular, I was surprised I needed to go dig up Lemma 1 instead of just using Tychonoff's theorem to get the needed compactness). </td></tr><tr><td comment_id="4010628"> (2) No, the point is that we are assuming for a contradiction that <span class="math-container" id="18103251" visual_id="167347"><math alttext="x_{1},\dots,x_{n+1}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow></semantics></math></span> is linearly dependent over <span class="math-container" id="18103255" visual_id="319"><math alttext="T" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi></semantics></math></span>.  Since <span class="math-container" id="18103253" visual_id="380462"><math alttext="T\supseteq S" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>⊇</mo><mi>S</mi></mrow></semantics></math></span>, <span class="math-container" id="18103254" visual_id="7647"><math alttext="x_{1},\dots,x_{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></semantics></math></span> are linearly independent over <span class="math-container" id="18103255" visual_id="319"><math alttext="T" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi></semantics></math></span>, so the only way this can happen is if <span class="math-container" id="18103256" visual_id="24510"><math alttext="x_{n+1}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub></semantics></math></span> is a linear combination of them.  I'll edit to make this a bit clearer. </td></tr><tr><td comment_id="4015976"> A friend of mine suggested trying to use the Baire category theorem in some way. I believe it might work, but the resulting proof would probably be very similar to this one in spirit. </td></tr>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div id="duplicate">
<table>
<tbody>
</tbody>
</table>
</div>
<hr/>
<div id="related">
<table>
<tbody>
</tbody>
</table>
</div>
</div>
</div>
</body>
</html>
