<!DOCTYPE html>

<html>
<head>
<title>Please explain the intuition behind the dual problem in optimization.</title>
<link href="https://cdn.sstatic.net/Shared/stacks.css?v=079c5e1603be" rel="stylesheet" type="text/css"/>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript"> </script>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap.min.css" rel="stylesheet"/>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap-theme.min.css" rel="stylesheet"/>
<style>
        .row {
          display: block;
          margin-left: auto;
          margin-right: auto;
          width:50%;
        }
        tr {
          border:1px solid lightgrey;
        }
        </style>
</head>
<body>
<div>
<div class="row" id="question-title">
<h1> Please explain the intuition behind the dual problem in optimization. </h1>
<hr/>
</div>
<div class="row">
<div class="question">
<div id="question" question_id="223235">
<p>I've studied convex optimization pretty carefully, but don't feel that I have yet "grokked" the dual problem.  Here are some questions I would like to understand more deeply/clearly/simply:</p> <ol> <li>How would somebody think of the dual problem?  What thought process would lead someone to consider the dual problem and to recognize that it's valuable/interesting?</li> <li>In the case of a convex optimization problem, is there any obvious reason to expect that strong duality should (usually) hold? </li> <li>It often happens that the dual of the dual problem is the primal problem.  However, this seems like a complete surprise to me.  Is there any intuitive reason to expect that this should happen?</li> <li>Does the use of the word "dual" or "duality" in optimization have anything to do with the dual space in linear algebra?  Or are they just different concepts that go by the same name.  What about the use of the word "dual" in projective geometry — is there a connection there?</li> <li>You can define the dual problem and prove theorems about strong duality without ever mentioning the Fenchel conjugate.  For example, Boyd and Vandenberghe prove a strong duality theorem without mentioning the Fenchel conjugate in their proof.  And yet, people often talk as if the Fenchel conjugate is somehow the "essence" of duality, and make it sound as if the whole theory of duality is based on the Fenchel conjugate.  Why is the Fenchel conjugate considered to have such fundamental importance?</li> </ol> <p>Note: I will now describe my current level of understanding of the intuition behind the dual problem.  Please tell me if you think I might be missing any basic insights.</p> <p>I have read the excellent <a href="http://hss.caltech.edu/~gpf/#teaching" rel="noreferrer">notes</a> about convex optimization by Guilherme Freitas, and in particular the part about "penalty intuition".  When we are trying to solve</p> <p><span class="math-container">\begin{align*} \text{minimize} &amp;\quad f(x) \\ \text{such that} &amp; \quad h(x) \leq 0 \end{align*}</span></p> <p>one might try to eliminate the constraints by introducing a penalty when constraints are violated.  This gives us the new unconstrained problem</p> <p><span class="math-container">\begin{equation} \text{minimize} \quad f(x) + \langle \lambda ,h(x) \rangle \end{equation}</span></p> <p>where <span class="math-container" id="2522060" visual_id="12426"><math alttext="\lambda\geq 0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>≥</mo><mn>0</mn></mrow></semantics></math></span>. It's not hard to see that for a given <span class="math-container" id="2522061" visual_id="12426"><math alttext="\lambda\geq 0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>≥</mo><mn>0</mn></mrow></semantics></math></span>, the optimal value of this unconstrained problem is less than or equal to the optimal value for the constrained problem.  This gives us a new problem — find <span class="math-container" id="2522062" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span> so that the optimal value for the unconstrained problem is as large as possible.  That is one way to imagine how somebody might have thought of the dual problem.  Is this the best intuition for where the dual problem comes from?</p> <p>Another viewpoint: the KKT conditions can be derived using what Freitas calls the "geometric intuition".  Then, if we knew the value of the multipliers <span class="math-container" id="2522063" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span>, it would be (often) much easier to find <span class="math-container" id="2522064" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span>.  So, a new problem is to find <span class="math-container" id="2522065" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span>.  And if we can somehow recognize that <span class="math-container" id="2522066" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span> is a maximizer for the dual problem, then this suggests that we might try solving the dual problem.</p> <p>Please explain or give references to any intuition that you think I might find interesting, even if it's not directly related to what I asked.</p>
</div>
<hr/>
<div id="tags">
<span> optimization </span><span> convex-optimization </span><span> intuition </span><span> lagrange-multiplier </span><span> karush-kuhn-tucker </span>
</div>
<hr/>
<div id="question-comments">
<table>
<tbody>
<tr><td comment_id="1311837"> This is pretty late, but in case anyone'd like a different perspective, you might like to have a look at the (my) answer to [this question](http://math.stackexchange.com/questions/622552/recovering-the-solution-of-optimization-problem-from-the-dual-problem/622638#622638). Also, I've always thought that [these slides](http://www.ifor.math.ethz.ch/teaching/Courses/Spring_2013/Convex_Optimization/Slides) introduce duality very well (and concisely). </td></tr><tr><td comment_id="4583156"> The link for the slides is dead as the lecture is no longer offered. However the wayback machine saved them: https://web-beta.archive.org/web/20141227023221/http://www.ifor.math.ethz.ch:80/teaching/Courses/Spring_2013/Convex_Optimization/Slides </td></tr>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div class="answer">
<div answer_id="235503" id="answer">
<p>I'll take a crack at a couple of these questions (some of them are hard and would require more thought).</p> <p>1) Here's a nice economic interpretation of duality (being a bit "fast and loose" with the details).  Let's say <span class="math-container" id="2522126" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span> represents the design of a widget, and <span class="math-container" id="2522127" visual_id="1805"><math alttext="f(x)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> is the cost you will incur producing it.  <span class="math-container" id="2522128" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span> must satisfy "design constraints" given by <span class="math-container" id="2522129" visual_id="1169704"><math alttext="h(x)\leq 0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>h</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>≤</mo><mn>0</mn></mrow></semantics></math></span> (suppose for simplicity that we have only 1 constraint function).  Out of curiosity, you decide to try farming out production: another company agrees to produce your thingy <span class="math-container" id="2522130" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span> and "charge" you <span class="math-container" id="2522131" visual_id="1805"><math alttext="f(x)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> for it.  Their goal is ultimately to maximize profit, but they can't charge you more than you would spend doing it yourself.  So given a fixed <span class="math-container" id="2522132" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span>, they need to find the design <span class="math-container" id="2522133" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span> that minimizes <span class="math-container" id="2522134" visual_id="5217301"><math alttext="f(x)+\lambda h(x)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mrow><mi>λ</mi><mo>⁢</mo><mi>h</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></semantics></math></span>.  If they don't, you'll be able to find a feasible design <span class="math-container" id="2522135" visual_id="68"><math alttext="y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi></semantics></math></span> that has a lower cost <span class="math-container" id="2522136" visual_id="525476"><math alttext="f(y)&amp;lt;f(x)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><mo>&lt;</mo></mrow><mrow><mi>f</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></semantics></math></span>, and thus you'll make the widget yourself.  Now that this company can do at least as good as you, they'll set about maximizing their profit by varying <span class="math-container" id="2522137" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span> (maybe <span class="math-container" id="2522138" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span> corresponds to a different process or something).</p> <p>This interpretation is similar to that in Boyd and Vandenberghe, 5.4.4.  Also I find 'game theoretic' interpretations helpful - the primal problem is your strategy while the dual corresponds to an opponent's strategy.</p> <p>2) I don't have an intuitive answer for this other than to say that strong duality is equivalent to existence of a saddle point of the Lagrangian. </p> <p>3) For convex problems this makes sense because applying the convex conjugate (Fenchel transform) twice returns the 'convexification' of the original objective function, which is the same as the original function in most 'nice' situations.  </p> <p>4) Yes, but you definitely have to be careful here.  The dual of a vector space is formally defined as the space of all continuous linear functionals on that space, and this concept lives 100% independently of optimization theory.  However, you're correct to notice that the dual of a vector space does arise in the statement of the dual of an optimization problem.  Let me explain: define <span class="math-container" id="2522139" visual_id="125311"><math alttext="X=\mathbb{R}^{n}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><msup><mi>ℝ</mi><mi>n</mi></msup></mrow></semantics></math></span> and <span class="math-container" id="2522140" visual_id="2638845"><math alttext="Y=\mathbb{R}^{m}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><msup><mi>ℝ</mi><mi>m</mi></msup></mrow></semantics></math></span> and consider the problem:  </p> <p><span class="math-container" id="2522141" visual_id="5217302"><math alttext="\text{minimize}\quad f(x)\\ \text{such that}\quad h(x)\leq 0\\ x\in X,\;f:X\rightarrow\mathbb{R},\\ h:X\rightarrow Y." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>minimize</mtext><mo mathvariant="italic" separator="true"> </mo><mi>f</mi><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mtext>such that</mtext><mo mathvariant="italic" separator="true"> </mo><mi>h</mi><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo>≤</mo><mn>0</mn><mi>x</mi><mo>∈</mo><mi>X</mi><mo rspace="5.3pt">,</mo><mi>f</mi><mo>:</mo><mi>X</mi><mo>→</mo><mi>ℝ</mi><mo>,</mo><mi>h</mi><mo>:</mo><mi>X</mi><mo>→</mo><mi>Y</mi><mo>.</mo></mrow></semantics></math></span> Then, this problem has the following dual: </p> <p><span class="math-container" id="2522142" visual_id="5217303"><math alttext="\max_{\lambda}\quad\inf_{x\in X}\{f(x)+\langle\lambda,h(x)\rangle\}\\ \text{such that}\quad\lambda_{i}\geq 0,~{}~{}\forall i:0\leq i\leq m" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>max</mi><mi>λ</mi></msub><mo mathvariant="italic" separator="true"> </mo><msub><mo>inf</mo><mrow><mi>x</mi><mo>∈</mo><mi>X</mi></mrow></msub><mrow><mo stretchy="false">{</mo><mi>f</mi><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo>+</mo><mrow><mo stretchy="false">⟨</mo><mi>λ</mi><mo>,</mo><mi>h</mi><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mo stretchy="false">⟩</mo></mrow><mo stretchy="false">}</mo></mrow><mtext>such that</mtext><mo mathvariant="italic" separator="true"> </mo><msub><mi>λ</mi><mi>i</mi></msub><mo>≥</mo><mn>0</mn><mo rspace="9.1pt">,</mo><mo>∀</mo><mi>i</mi><mo>:</mo><mn>0</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>m</mi></mrow></semantics></math></span> Now, "formally", <span class="math-container" id="2522143" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span> is an element of the dual space of <span class="math-container" id="2522144" visual_id="375"><math alttext="Y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi></semantics></math></span>, since we're considering an inner product of the form <span class="math-container" id="2522145" visual_id="5217304"><math alttext="\langle\lambda,y\rangle" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi>λ</mi><mo>,</mo><mi>y</mi><mo stretchy="false">⟩</mo></mrow></semantics></math></span> where <span class="math-container" id="2522146" visual_id="16123"><math alttext="y\in Y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>∈</mo><mi>Y</mi></mrow></semantics></math></span>, and hence can think of this as a continuous linear functional on <span class="math-container" id="2522147" visual_id="375"><math alttext="Y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi></semantics></math></span>.  But here <span class="math-container" id="2522148" visual_id="375"><math alttext="Y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi></semantics></math></span> is finite dimensional, so (by the Riesz representation theorem) <span class="math-container" id="2522149" visual_id="67615"><math alttext="Y^{*}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Y</mi><mo>*</mo></msup></semantics></math></span> is actually isomorphic to <span class="math-container" id="2522150" visual_id="375"><math alttext="Y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi></semantics></math></span>, so the distinction isn't really necessary and you haven't gained anything by thinking of <span class="math-container" id="2522151" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span> as being an element of the dual space.  It's possible that in infinite dimensional problems where <span class="math-container" id="2522152" visual_id="67615"><math alttext="Y^{*}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Y</mi><mo>*</mo></msup></semantics></math></span> is not isomorphic to <span class="math-container" id="2522153" visual_id="375"><math alttext="Y" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi></semantics></math></span> you get something out of this, but I can't think of a good example.</p> <p>To my knowledge, there is zero connection between duality in projective geometry and duality in optimization.  Duality in projective geometry is more a statement about the bijection between points and rays that defines projective space.  "Duality" in math really just means having 2 ways to think about a problem - it's as overused as words like "fundamental" and "canonical".  Another classical example of duality comes from fluid dynamics and PDE - "Eulerian" coordinates vs. 'Lagrangian' coordinates.</p> <p>5) For convex problems, I would agree that the convex conjugate is key, though in general I'm not sure it helps a lot with the 'general' idea of duality since (a) not all interesting problems are convex and (b) the convex conjugate is legendarily hard to gain intuition for.   Historically this 'fundamental importance' of the convex conjugate might be traced to physics, where it turns out that a lot of interesting physical systems have a convex 'Lagrangian' describing their total energy.  The equations of motion can then be phrased essentially as a convex minimization problem with respect to this Lagrangian.  The convex conjugate function, it then turns out, is what is called the 'Hamiltonian', which leads to an entirely different (one might say 'dual') formulation of the equations of physics. Thus we have yet again two ways to approach the same problem!</p> <p>Hope this was somewhat useful to you.</p>
</div>
<hr/>
<div id="answer-comments">
<table>
<tbody>
<tr><td comment_id="521904"> Yes, very helpful, thank you! </td></tr><tr><td comment_id="1284909"> I wonder why do we need to solve the dual problem, why not just solve the primal one directly? Because the dual one is often more tractable? </td></tr><tr><td comment_id="1285453"> @loganecolss yes, or more commonly various saddle point formulations are more computationally tractable. The dual can also offer a useful theoretical perspective, especially in problems of economic interest, and finally the dual (actually the lagrangian/saddle point problem) are crucial for proving things like existence and characterizing solutions. </td></tr><tr><td comment_id="4880255"> @loganecolss  **In my opinion**  Saying that solving dual problem is easier,  is ridiculous !  Even if  we restrict ourself to those problems where constructing dual problem does not require much effort, like LPs  then we probably have symmetric property  i.e,  <span class="math-container" id="2522154" visual_id="5217305"><math alttext="\text{dual}~{}\text{dual}=\text{primal}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mpadded width="+3.3pt"><mtext>dual</mtext></mpadded><mo>⁢</mo><mtext>dual</mtext></mrow><mo>=</mo><mtext>primal</mtext></mrow></semantics></math></span>   That's enough to reject this claim which is widely used in optimization community ! </td></tr>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div id="duplicate">
<table>
<tbody>
</tbody>
</table>
</div>
<hr/>
<div id="related">
<table>
<tbody>
<tr><td post_id="332162"> How to understand convex duality intuitively </td></tr><tr><td post_id="1486430"> How is the Lagrangian related to the perturbation function? </td></tr><tr><td post_id="2225932"> Physical interpretation and notions about conjugate function? </td></tr><tr><td post_id="2540332"> Understanding Legendre-fenchel Transform, looking for an easy example and intuition </td></tr><tr><td post_id="2234255"> Geometric interpretation of duality in optimization </td></tr><tr><td post_id="1744664"> How to form a dual problem in convex optimization (in a broad view) </td></tr><tr><td post_id="1863709"> Geometric interpretation of linear programming dual </td></tr><tr><td post_id="622552"> Recovering the solution of optimization problem from the dual problem </td></tr><tr><td post_id="1910876"> How to obtain the dual of a Lagrangian? </td></tr><tr><td post_id="329501"> the dual of the dual is the primal? </td></tr><tr><td post_id="948862"> Fenchel dual vs Lagrange dual </td></tr>
</tbody>
</table>
</div>
</div>
</div>
</body>
</html>
