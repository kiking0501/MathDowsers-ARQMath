<!DOCTYPE html>

<html>
<head>
<title>Please explain the intuition behind the dual problem in optimization.</title>
<link href="https://cdn.sstatic.net/Shared/stacks.css?v=079c5e1603be" rel="stylesheet" type="text/css"/>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG.js" type="text/javascript"> </script>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap.min.css" rel="stylesheet"/>
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.0/css/bootstrap-theme.min.css" rel="stylesheet"/>
<style>
        .row {
          display: block;
          margin-left: auto;
          margin-right: auto;
          width:50%;
        }
        tr {
          border:1px solid lightgrey;
        }
        </style>
</head>
<body>
<div>
<div class="row" id="question-title">
<h1> Please explain the intuition behind the dual problem in optimization. </h1>
<hr/>
</div>
<div class="row">
<div class="question">
<div id="question" question_id="223235">
<p>I've studied convex optimization pretty carefully, but don't feel that I have yet "grokked" the dual problem.  Here are some questions I would like to understand more deeply/clearly/simply:</p> <ol> <li>How would somebody think of the dual problem?  What thought process would lead someone to consider the dual problem and to recognize that it's valuable/interesting?</li> <li>In the case of a convex optimization problem, is there any obvious reason to expect that strong duality should (usually) hold? </li> <li>It often happens that the dual of the dual problem is the primal problem.  However, this seems like a complete surprise to me.  Is there any intuitive reason to expect that this should happen?</li> <li>Does the use of the word "dual" or "duality" in optimization have anything to do with the dual space in linear algebra?  Or are they just different concepts that go by the same name.  What about the use of the word "dual" in projective geometry — is there a connection there?</li> <li>You can define the dual problem and prove theorems about strong duality without ever mentioning the Fenchel conjugate.  For example, Boyd and Vandenberghe prove a strong duality theorem without mentioning the Fenchel conjugate in their proof.  And yet, people often talk as if the Fenchel conjugate is somehow the "essence" of duality, and make it sound as if the whole theory of duality is based on the Fenchel conjugate.  Why is the Fenchel conjugate considered to have such fundamental importance?</li> </ol> <p>Note: I will now describe my current level of understanding of the intuition behind the dual problem.  Please tell me if you think I might be missing any basic insights.</p> <p>I have read the excellent <a href="http://hss.caltech.edu/~gpf/#teaching" rel="noreferrer">notes</a> about convex optimization by Guilherme Freitas, and in particular the part about "penalty intuition".  When we are trying to solve</p> <p><span class="math-container">\begin{align*} \text{minimize} &amp;\quad f(x) \\ \text{such that} &amp; \quad h(x) \leq 0 \end{align*}</span></p> <p>one might try to eliminate the constraints by introducing a penalty when constraints are violated.  This gives us the new unconstrained problem</p> <p><span class="math-container">\begin{equation} \text{minimize} \quad f(x) + \langle \lambda ,h(x) \rangle \end{equation}</span></p> <p>where <span class="math-container" id="2522060" visual_id="12426"><math alttext="\lambda\geq 0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>≥</mo><mn>0</mn></mrow></semantics></math></span>. It's not hard to see that for a given <span class="math-container" id="2522061" visual_id="12426"><math alttext="\lambda\geq 0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>≥</mo><mn>0</mn></mrow></semantics></math></span>, the optimal value of this unconstrained problem is less than or equal to the optimal value for the constrained problem.  This gives us a new problem — find <span class="math-container" id="2522062" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span> so that the optimal value for the unconstrained problem is as large as possible.  That is one way to imagine how somebody might have thought of the dual problem.  Is this the best intuition for where the dual problem comes from?</p> <p>Another viewpoint: the KKT conditions can be derived using what Freitas calls the "geometric intuition".  Then, if we knew the value of the multipliers <span class="math-container" id="2522063" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span>, it would be (often) much easier to find <span class="math-container" id="2522064" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span>.  So, a new problem is to find <span class="math-container" id="2522065" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span>.  And if we can somehow recognize that <span class="math-container" id="2522066" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span> is a maximizer for the dual problem, then this suggests that we might try solving the dual problem.</p> <p>Please explain or give references to any intuition that you think I might find interesting, even if it's not directly related to what I asked.</p>
</div>
<hr/>
<div id="tags">
<span> optimization </span><span> convex-optimization </span><span> intuition </span><span> lagrange-multiplier </span><span> karush-kuhn-tucker </span>
</div>
<hr/>
<div id="question-comments">
<table>
<tbody>
<tr><td comment_id="1311837"> This is pretty late, but in case anyone'd like a different perspective, you might like to have a look at the (my) answer to [this question](http://math.stackexchange.com/questions/622552/recovering-the-solution-of-optimization-problem-from-the-dual-problem/622638#622638). Also, I've always thought that [these slides](http://www.ifor.math.ethz.ch/teaching/Courses/Spring_2013/Convex_Optimization/Slides) introduce duality very well (and concisely). </td></tr><tr><td comment_id="4583156"> The link for the slides is dead as the lecture is no longer offered. However the wayback machine saved them: https://web-beta.archive.org/web/20141227023221/http://www.ifor.math.ethz.ch:80/teaching/Courses/Spring_2013/Convex_Optimization/Slides </td></tr>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div class="answer">
<div answer_id="2977420" id="answer">
<p>A lot of great explanations.</p> <p>The easiest way to get in-depth knowledge, I think, however, is just to study chapter 5 of this <a href="http://stanford.edu/~boyd/cvxbook/" rel="nofollow noreferrer">book</a>, written by Stanford professor Stephen Boyd.</p> <p>You will realize that the dual problem is nothing more than replacing <em>hard</em> constraints (of the form <span class="math-container" id="2522208" visual_id="2553090"><math alttext="f_{i}(x)\leq 0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>≤</mo><mn>0</mn></mrow></semantics></math></span> and <span class="math-container" id="2522209" visual_id="518845"><math alttext="h_{i}(x)=0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow></semantics></math></span>) by <em>soft</em> constraints, which are linear functions of <span class="math-container" id="2522210" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span>, such as <span class="math-container" id="2522211" visual_id="5217330"><math alttext="\lambda_{i}(x)=\lambda_{i}x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>λ</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>λ</mi><mi>i</mi></msub><mo>⁢</mo><mi>x</mi></mrow></mrow></semantics></math></span> and <span class="math-container" id="2522212" visual_id="5217331"><math alttext="\nu_{i}(x)=\nu_{i}x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>ν</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mi>ν</mi><mi>i</mi></msub><mo>⁢</mo><mi>x</mi></mrow></mrow></semantics></math></span>. </p> <p>In the book, he uses the variable <span class="math-container" id="2522213" visual_id="506"><math alttext="u" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>u</mi></semantics></math></span>, and he formalizes these <em>hard</em> constraints with <em>indicator functions</em> <span class="math-container" id="2522214" visual_id="5217332"><math alttext="I_{-}{}(u)," class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>I</mi><mo>-</mo></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo></mrow></semantics></math></span> defined to be zero for <span class="math-container" id="2522215" visual_id="317953"><math alttext="u\leq 0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo>≤</mo><mn>0</mn></mrow></semantics></math></span> and <span class="math-container" id="2522216" visual_id="2076"><math alttext="\infty" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi mathvariant="normal">∞</mi></semantics></math></span> for <span class="math-container" id="2522217" visual_id="62743"><math alttext="u&amp;gt;0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>u</mi><mo>&gt;</mo></mrow><mn>0</mn></mrow></semantics></math></span>, and <span class="math-container" id="2522218" visual_id="5217333"><math alttext="I_{0}{}(u)," class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>I</mi><mn>0</mn></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo></mrow></mrow><mo>,</mo></mrow></semantics></math></span> defined to be <span class="math-container" id="2522219" visual_id="2076"><math alttext="\infty" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi mathvariant="normal">∞</mi></semantics></math></span> everywhere except at <span class="math-container" id="2522220" visual_id="23476"><math alttext="u=0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo>=</mo><mn>0</mn></mrow></semantics></math></span>.</p> <p>Note that the linear functions <span class="math-container" id="2522221" visual_id="5217334"><math alttext="\lambda_{i}u" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mi>i</mi></msub><mo>⁢</mo><mi>u</mi></mrow></semantics></math></span> and <span class="math-container" id="2522222" visual_id="5217335"><math alttext="\nu_{i}u" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ν</mi><mi>i</mi></msub><mo>⁢</mo><mi>u</mi></mrow></semantics></math></span> are always <span class="math-container" id="2522223" visual_id="4229"><math alttext="\leq" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mo>≤</mo></semantics></math></span> the respective indicator functions. Therefore:</p> <blockquote> <p>Clearly the approximation of the indicator function <span class="math-container" id="2522224" visual_id="5217336"><math alttext="I_{-}{}(u)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mo>-</mo></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> with a linear function <span class="math-container" id="2522225" visual_id="5217334"><math alttext="λ_{i}u" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mi>i</mi></msub><mo>⁢</mo><mi>u</mi></mrow></semantics></math></span> is rather poor. But the linear function is at least an <em>underestimator</em> of the that the dual function yields a lower bound on the optimal value of the original indicator function. Since <span class="math-container" id="2522226" visual_id="5217337"><math alttext="λ_{i}u\leq I_{-}{}(u)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>λ</mi><mi>i</mi></msub><mo>⁢</mo><mi>u</mi></mrow><mo>≤</mo><mrow><msub><mi>I</mi><mo>-</mo></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></semantics></math></span> and <span class="math-container" id="2522227" visual_id="5217338"><math alttext="\nu_{i}u\leq I_{0}(u)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>ν</mi><mi>i</mi></msub><mo>⁢</mo><mi>u</mi></mrow><mo>≤</mo><mrow><msub><mi>I</mi><mn>0</mn></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo></mrow></mrow></mrow></semantics></math></span> for all u, we see immediately that the dual function yields a lower bound on the optimal value of the original problem.</p> </blockquote> <p>This means that if <span class="math-container" id="2522228" visual_id="132405"><math alttext="\lambda_{i}&amp;gt;0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>λ</mi><mi>i</mi></msub><mo>&gt;</mo></mrow><mn>0</mn></mrow></semantics></math></span>,  for every acceptable value <span class="math-container" id="2522229" visual_id="33140"><math alttext="\tilde{x}" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover accent="true"><mi>x</mi><mo stretchy="false">~</mo></mover></semantics></math></span> (i.e. a value that satisfies the constraints <span class="math-container" id="2522230" visual_id="524382"><math alttext="f_{i}(\tilde{x})\leq 0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo stretchy="false">~</mo></mover><mo stretchy="false">)</mo></mrow></mrow><mo>≤</mo><mn>0</mn></mrow></semantics></math></span> and <span class="math-container" id="2522231" visual_id="524383"><math alttext="h_{i}(\tilde{x})=0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo stretchy="false">~</mo></mover><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mn>0</mn></mrow></semantics></math></span>), the resulting values of  <span class="math-container" id="2522232" visual_id="5217339"><math alttext="L(\tilde{x},\nu,\lambda)=f_{0}(\tilde{x})+\sum_{i}\lambda_{i}f_{i}(\tilde{x})+% \sum_{i}\nu_{i}h_{i}(\tilde{x})" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>L</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo stretchy="false">~</mo></mover><mo>,</mo><mi>ν</mi><mo>,</mo><mi>λ</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>f</mi><mn>0</mn></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo stretchy="false">~</mo></mover><mo stretchy="false">)</mo></mrow></mrow><mo>+</mo><mrow><msub><mo largeop="true" symmetric="true">∑</mo><mi>i</mi></msub><mrow><msub><mi>λ</mi><mi>i</mi></msub><mo>⁢</mo><msub><mi>f</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo stretchy="false">~</mo></mover><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>+</mo><mrow><msub><mo largeop="true" symmetric="true">∑</mo><mi>i</mi></msub><mrow><msub><mi>ν</mi><mi>i</mi></msub><mo>⁢</mo><msub><mi>h</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo stretchy="false">~</mo></mover><mo stretchy="false">)</mo></mrow></mrow></mrow></mrow></mrow></semantics></math></span> are always <span class="math-container" id="2522233" visual_id="5217340"><math alttext="L(\tilde{x},\nu,\lambda)\leq f_{0}(\tilde{x})," class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><mi>L</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo stretchy="false">~</mo></mover><mo>,</mo><mi>ν</mi><mo>,</mo><mi>λ</mi><mo stretchy="false">)</mo></mrow></mrow><mo>≤</mo><mrow><msub><mi>f</mi><mn>0</mn></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo stretchy="false">~</mo></mover><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>,</mo></mrow></semantics></math></span> where the minimization of <span class="math-container" id="2522234" visual_id="29704"><math alttext="f_{0}(x)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>0</mn></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> was the original optimization problem.</p> <hr/> <p><strong>example: linear Programming</strong></p> <p>For linear programming (LP), the function to be minimized is <span class="math-container" id="2522235" visual_id="5217341"><math alttext="f_{0}(x)=c^{T}x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>f</mi><mn>0</mn></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msup><mi>c</mi><mi>T</mi></msup><mo>⁢</mo><mi>x</mi></mrow></mrow></semantics></math></span> and the constraints are of the form <span class="math-container" id="2522236" visual_id="5217342"><math alttext="\left\{\begin{aligned} \displaystyle Ax&amp;\displaystyle amp;=b\\ \displaystyle x&amp;\displaystyle amp;\geq 0\end{aligned}\right.," class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>{</mo><mtable columnspacing="0pt" rowspacing="0pt"><mtr><mtd columnalign="right"><mrow><mi>A</mi><mo>⁢</mo><mi>x</mi></mrow></mtd><mtd columnalign="left"><mrow><mi>a</mi><mi>m</mi><mi>p</mi><mo>;</mo><mo>=</mo><mi>b</mi></mrow></mtd></mtr><mtr><mtd columnalign="right"><mi>x</mi></mtd><mtd columnalign="left"><mrow><mi>a</mi><mi>m</mi><mi>p</mi><mo>;</mo><mo>≥</mo><mn>0</mn></mrow></mtd></mtr></mtable><mo>,</mo></mrow></semantics></math></span></p> <p>which leads to the Lagrangian <span class="math-container" id="2522237" visual_id="5217343"><math alttext="L(x,\lambda,\nu)=c^{T}x+\nu^{T}(Ax-b)-\lambda^{T}x." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><mi>L</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>λ</mi><mo>,</mo><mi>ν</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mrow><msup><mi>c</mi><mi>T</mi></msup><mo>⁢</mo><mi>x</mi></mrow><mo>+</mo><mrow><msup><mi>ν</mi><mi>T</mi></msup><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mrow><mrow><mi>A</mi><mo>⁢</mo><mi>x</mi></mrow><mo>-</mo><mi>b</mi></mrow><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>-</mo><mrow><msup><mi>λ</mi><mi>T</mi></msup><mo>⁢</mo><mi>x</mi></mrow></mrow></mrow><mo>.</mo></mrow></semantics></math></span> (Note the minus sign in front of <span class="math-container" id="2522238" visual_id="664"><math alttext="\lambda" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi></semantics></math></span>: this is because we chose the conditions of type <span class="math-container" id="2522239" visual_id="2553090"><math alttext="f_{i}(x)\leq 0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mrow><mo>≤</mo><mn>0</mn></mrow></semantics></math></span> the other way around.)</p> <p>The terms in function of of <span class="math-container" id="2522240" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span> are all linear, so minimization in <span class="math-container" id="2522241" visual_id="67"><math alttext="x" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi></semantics></math></span> means setting them to 0: <span class="math-container" id="2522242" visual_id="5217344"><math alttext="c^{T}+\nu^{T}A-\lambda^{T}=0," class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><mrow><msup><mi>c</mi><mi>T</mi></msup><mo>+</mo><mrow><msup><mi>ν</mi><mi>T</mi></msup><mo>⁢</mo><mi>A</mi></mrow></mrow><mo>-</mo><msup><mi>λ</mi><mi>T</mi></msup></mrow><mo>=</mo><mn>0</mn></mrow><mo>,</mo></mrow></semantics></math></span> so that the dual function <span class="math-container" id="2522243" visual_id="1208056"><math alttext="g(\lambda,\nu)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>λ</mi><mo>,</mo><mi>ν</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span> becomes <span class="math-container" id="2522244" visual_id="5217345"><math alttext="g(\lambda,\nu)=\inf_{x}L(x,\lambda,\nu)=-\nu^{T}b," class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><mi>g</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>λ</mi><mo>,</mo><mi>ν</mi><mo stretchy="false">)</mo></mrow></mrow><mo>=</mo><mrow><msub><mo>inf</mo><mi>x</mi></msub><mo>⁡</mo><mrow><mi>L</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>λ</mi><mo>,</mo><mi>ν</mi><mo stretchy="false">)</mo></mrow></mrow></mrow><mo>=</mo><mrow><mo>-</mo><mrow><msup><mi>ν</mi><mi>T</mi></msup><mo>⁢</mo><mi>b</mi></mrow></mrow></mrow><mo>,</mo></mrow></semantics></math></span></p> <p>This is the dual problem: You have to maximize <span class="math-container" id="2522245" visual_id="1208056"><math alttext="g(\lambda,\nu)" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>⁢</mo><mrow><mo stretchy="false">(</mo><mi>λ</mi><mo>,</mo><mi>ν</mi><mo stretchy="false">)</mo></mrow></mrow></semantics></math></span>, the lower bound for the original minimization problem, subject to the last equation above, that can be transposed to <span class="math-container" id="2522246" visual_id="5217346"><math alttext="c+A^{T}\nu-\lambda=0," class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><mrow><mi>c</mi><mo>+</mo><mrow><msup><mi>A</mi><mi>T</mi></msup><mo>⁢</mo><mi>ν</mi></mrow></mrow><mo>-</mo><mi>λ</mi></mrow><mo>=</mo><mn>0</mn></mrow><mo>,</mo></mrow></semantics></math></span></p> <p>Finally, note that in order for this to be a true lower bound, we need <span class="math-container" id="2522247" visual_id="12426"><math alttext="\lambda\geq 0" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>≥</mo><mn>0</mn></mrow></semantics></math></span>, as discussed previously: You need to take the correct half-plane for the <em>soft</em> constraints to be always softer than the <em>hard</em> constraints.</p> <p>Combining this with the equation above then leads to the equations you will see in any textbook on LP:</p> <p>Maximize in <span class="math-container" id="2522248" visual_id="6894"><math alttext="\nu" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ν</mi></semantics></math></span> <span class="math-container" id="2522249" visual_id="5217347"><math alttext="-b^{T}\nu" class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>-</mo><mrow><msup><mi>b</mi><mi>T</mi></msup><mo>⁢</mo><mi>ν</mi></mrow></mrow></semantics></math></span> subject to <span class="math-container" id="2522250" visual_id="5217348"><math alttext="c+A^{T}\nu&amp;gt;0." class="ltx_Math" display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><mi>c</mi><mo>+</mo><mrow><msup><mi>A</mi><mi>T</mi></msup><mo>⁢</mo><mi>ν</mi><mo>&gt;</mo></mrow></mrow><mn>0</mn></mrow><mo>.</mo></mrow></semantics></math></span></p>
</div>
<hr/>
<div id="answer-comments">
<table>
<tbody>
</tbody>
</table>
</div>
</div>
<hr style="border-top: 3px double #8c8b8b"/>
</div>
<div class="row">
<div id="duplicate">
<table>
<tbody>
</tbody>
</table>
</div>
<hr/>
<div id="related">
<table>
<tbody>
<tr><td post_id="332162"> How to understand convex duality intuitively </td></tr><tr><td post_id="1486430"> How is the Lagrangian related to the perturbation function? </td></tr><tr><td post_id="2225932"> Physical interpretation and notions about conjugate function? </td></tr><tr><td post_id="2540332"> Understanding Legendre-fenchel Transform, looking for an easy example and intuition </td></tr><tr><td post_id="2234255"> Geometric interpretation of duality in optimization </td></tr><tr><td post_id="1744664"> How to form a dual problem in convex optimization (in a broad view) </td></tr><tr><td post_id="1863709"> Geometric interpretation of linear programming dual </td></tr><tr><td post_id="622552"> Recovering the solution of optimization problem from the dual problem </td></tr><tr><td post_id="1910876"> How to obtain the dual of a Lagrangian? </td></tr><tr><td post_id="329501"> the dual of the dual is the primal? </td></tr><tr><td post_id="948862"> Fenchel dual vs Lagrange dual </td></tr>
</tbody>
</table>
</div>
</div>
</div>
</body>
</html>
